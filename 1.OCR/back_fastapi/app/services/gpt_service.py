from openai import OpenAI
from typing import Optional
import asyncio
import time

from app.models.response import GPTResponse
from app.config.settings import settings
from app.core.exceptions import GPTException

class GPTService:
    def __init__(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not settings.OPENAI_API_KEY:
            raise GPTException("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = settings.OPENAI_MODEL
    
    async def analyze_text(self, text: str, prompt: str = "") -> GPTResponse:
        """í…ìŠ¤íŠ¸ ë¶„ì„ ë° GPT ì‘ë‹µ"""
        try:
            start_time = time.time()
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"{prompt}\n\ní…ìŠ¤íŠ¸: {text}"
            
            # ìƒˆë¡œìš´ GPT API í˜¸ì¶œ ë°©ì‹
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": full_prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # ì‘ë‹µ ì¶”ì¶œ
            gpt_response = response.choices[0].message.content
            usage = response.usage
            
            return GPTResponse(
                original_text=text,
                prompt=prompt,
                gpt_response=gpt_response,
                gpt_model=self.model,
                tokens_used=usage.total_tokens if usage else 0,
                response_time_ms=response_time_ms
            )
            
        except Exception as e:
            raise GPTException(f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_book_title(self, text: str) -> GPTResponse:
        """ì±… í‘œì§€ì—ì„œ ì œëª© ì¶”ì¶œ"""
        try:
            start_time = time.time()
            
            # ì±… ì œëª© ì¶”ë¡  ì „ë¬¸ê°€ ì—­í•  ì„¤ì • (ëŒ€í­ ë³´ê°•ëœ í”„ë¡¬í”„íŠ¸)
            system_prompt = """ë‹¹ì‹ ì€ ì±… ì œëª© ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì±… ì œëª©ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤.

ğŸ“š ì±… ì œëª© ì¶”ì¶œ ê·œì¹™:
1. **í•µì‹¬ í‚¤ì›Œë“œ ìš°ì„ **: ê°€ì¥ ì˜ë¯¸ ìˆê³  ë…ë¦½ì ì¸ ë‹¨ì–´ë‚˜ êµ¬ë¥¼ ì°¾ìœ¼ì„¸ìš”
2. **ê¸¸ì´ ê³ ë ¤**: ì±… ì œëª©ì€ ë³´í†µ 2-8ë‹¨ì–´ ì •ë„ì…ë‹ˆë‹¤
3. **ì–¸ì–´ ìš°ì„ ìˆœìœ„**: í•œê¸€ > ì˜ì–´ > ê¸°íƒ€ ìˆœì„œë¡œ ìš°ì„ í•˜ì„¸ìš”
4. **ë…¸ì´ì¦ˆ ì œê±°**: íŠ¹ìˆ˜ë¬¸ì, ìˆ«ì, ë¶ˆí•„ìš”í•œ ê¸°í˜¸ëŠ” ì œê±°í•˜ì„¸ìš”
5. **ë¬¸ë§¥ ë¶„ì„**: ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ê°€ì¥ ì±… ì œëª©ë‹¤ìš´ ì¡°í•©ì„ ì°¾ìœ¼ì„¸ìš”
6. **ì¼ë°˜ì ì¸ ì±… ì œëª© íŒ¨í„´**: 
   - "~ì˜ ~" (ê²½í—˜ì˜ ë©¸ì¢…, ë§ˆìŒì˜ ê¸°ìˆ )
   - "~ë¡ " (ììœ ë¡ , ë¯¼ì£¼ì£¼ì˜ë¡ )
   - "~í•˜ë‹¤" (ì‹¯ë‹¤ë¥´íƒ€, ìœ„ë²„ë©˜ì‰¬)
   - ë‹¨ì¼ ë‹¨ì–´ (ë„¥ì„œìŠ¤, ììœ )

ğŸ” ì¶”ì¶œ ê³¼ì •:
1. í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì‹ë³„
2. ì±… ì œëª© íŒ¨í„´ì— ë§ëŠ” ì¡°í•©ì„ ì°¾ê¸°
3. ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ì™„ì„±ë„ ë†’ì€ ì œëª© ì„ íƒ
4. í™•ì‹ ì´ ì—†ìœ¼ë©´ "ì¶”ì •:" í‘œê¸°

âŒ í”¼í•´ì•¼ í•  ê²ƒë“¤:
- ì €ìëª…, ì¶œíŒì‚¬ëª…
- ë¶€ì œëª©ì´ë‚˜ ì„¤ëª…ë¬¸
- ë„ˆë¬´ ê¸´ ë¬¸ì¥
- ì˜ë¯¸ ì—†ëŠ” ì¡°í•©"""
            
            user_prompt = f"""ë‹¤ìŒì€ ì±… í‘œì§€ì—ì„œ OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ìœ„ì˜ ê·œì¹™ì„ ë”°ë¼ ê°€ì¥ ì±… ì œëª©ì¼ í™•ë¥ ì´ ë†’ì€ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ğŸ“– ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {text}

ğŸ’¡ íŒíŠ¸: 
- ë…¸ì´ì¦ˆê°€ ë§ì•„ë„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ë³´ì„¸ìš”
- í•œê¸€ê³¼ ì˜ì–´ê°€ ì„ì—¬ìˆìœ¼ë©´ í•œê¸€ì„ ìš°ì„ í•˜ì„¸ìš”
- ì±… ì œëª©ì€ ë³´í†µ ê°„ê²°í•˜ê³  ì˜ë¯¸ê°€ ëª…í™•í•©ë‹ˆë‹¤
- ì „ì²´ì ì¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¶”ë¡ í•˜ì„¸ìš”"""
            
            # ìƒˆë¡œìš´ GPT API í˜¸ì¶œ ë°©ì‹
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=300,
                temperature=0.1  # ë§¤ìš° ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
            )
            
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # ì‘ë‹µ ì¶”ì¶œ
            gpt_response = response.choices[0].message.content
            usage = response.usage
            
            # ì‘ë‹µ í›„ì²˜ë¦¬: "ì¶”ì •:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ì œëª©ë§Œ ì¶”ì¶œ
            cleaned_response = self._clean_book_title_response(gpt_response)
            
            return GPTResponse(
                original_text=text,
                prompt="ì±… ì œëª© ì¶”ì¶œ",
                gpt_response=cleaned_response,
                gpt_model=self.model,
                tokens_used=usage.total_tokens if usage else 0,
                response_time_ms=response_time_ms
            )
            
        except Exception as e:
            raise GPTException(f"ì±… ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def summarize_text(self, text: str) -> GPTResponse:
        """í…ìŠ¤íŠ¸ ìš”ì•½"""
        prompt = "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:"
        return await self.analyze_text(text, prompt)
    
    async def translate_text(self, text: str, target_language: str = "í•œêµ­ì–´") -> GPTResponse:
        """í…ìŠ¤íŠ¸ ë²ˆì—­"""
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {target_language}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”:"
        return await self.analyze_text(text, prompt)
    
    async def extract_keywords(self, text: str) -> GPTResponse:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        prompt = "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):"
        return await self.analyze_text(text, prompt)
    
    async def answer_question(self, text: str, question: str) -> GPTResponse:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€"""
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\nì§ˆë¬¸: {question}"
        return await self.analyze_text(text, prompt)
    
    def _clean_book_title_response(self, response: str) -> str:
        """ì±… ì œëª© ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì‹¤ì œ ì œëª©ë§Œ ì¶”ì¶œ"""
        if not response:
            return ""
        
        # "ì¶”ì •:" ì œê±°
        if "ì¶”ì •:" in response:
            response = response.replace("ì¶”ì •:", "").strip()
        
        # "ì œëª©:" ì œê±°
        if "ì œëª©:" in response:
            response = response.replace("ì œëª©:", "").strip()
        
        # ë”°ì˜´í‘œ ì œê±°
        response = response.strip('"\'')
        
        # ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ê³µë°± ì •ë¦¬
        response = " ".join(response.split())
        
        return response
    
    async def batch_analyze(self, texts: list, prompt: str = "") -> list[GPTResponse]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¼ê´„ ë¶„ì„"""
        try:
            tasks = [self.analyze_text(text, prompt) for text in texts]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    processed_results.append(
                        GPTResponse(
                            original_text=texts[i],
                            prompt=prompt,
                            gpt_response=f"ì˜¤ë¥˜ ë°œìƒ: {str(result)}",
                            gpt_model=self.model,
                            tokens_used=0,
                            response_time_ms=0
                        )
                    )
                else:
                    processed_results.append(result)
            
            return processed_results
            
        except Exception as e:
            raise GPTException(f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}") 