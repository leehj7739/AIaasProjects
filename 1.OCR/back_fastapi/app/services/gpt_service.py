from openai import OpenAI
from typing import Optional
import asyncio
import time
import re

from app.models.response import GPTResponse
from app.config.settings import settings
from app.core.exceptions import GPTException

class GPTService:
    def __init__(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not settings.OPENAI_API_KEY:
            raise GPTException("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = settings.OPENAI_MODEL
    
    async def analyze_text(self, text: str, prompt: str = "") -> GPTResponse:
        """í…ìŠ¤íŠ¸ ë¶„ì„ ë° GPT ì‘ë‹µ"""
        try:
            start_time = time.time()
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"{prompt}\n\ní…ìŠ¤íŠ¸: {text}"
            
            # ìƒˆë¡œìš´ GPT API í˜¸ì¶œ ë°©ì‹
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": full_prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # ì‘ë‹µ ì¶”ì¶œ
            gpt_response = response.choices[0].message.content
            usage = response.usage
            
            return GPTResponse(
                original_text=text,
                prompt=prompt,
                gpt_response=gpt_response,
                gpt_model=self.model,
                tokens_used=usage.total_tokens if usage else 0,
                response_time_ms=response_time_ms
            )
            
        except Exception as e:
            raise GPTException(f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_book_title(self, text: str) -> GPTResponse:
        """ì±… í‘œì§€ì—ì„œ ì œëª© ì¶”ì¶œ"""
        try:
            start_time = time.time()
            
            # ì±… ì œëª© ì¶”ë¡  ì „ë¬¸ê°€ ì—­í•  ì„¤ì • (ëŒ€í­ ë³´ê°•ëœ í”„ë¡¬í”„íŠ¸)
            system_prompt = """ë‹¹ì‹ ì€ ì±… ì œëª© ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì±… ì œëª©ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤.

ğŸ“š ì±… ì œëª© ì¶”ì¶œ ê·œì¹™:
1. **í•µì‹¬ í‚¤ì›Œë“œ ìš°ì„ **: ê°€ì¥ ì˜ë¯¸ ìˆê³  ë…ë¦½ì ì¸ ë‹¨ì–´ë‚˜ êµ¬ë¥¼ ì°¾ìœ¼ì„¸ìš”
2. **ê¸¸ì´ ê³ ë ¤**: ì±… ì œëª©ì€ ë³´í†µ 2-8ë‹¨ì–´ ì •ë„ì…ë‹ˆë‹¤
3. **ì–¸ì–´ ìš°ì„ ìˆœìœ„**: í•œê¸€ > ì˜ì–´ > ê¸°íƒ€ ìˆœì„œë¡œ ìš°ì„ í•˜ì„¸ìš”
4. **ë…¸ì´ì¦ˆ ì œê±°**: íŠ¹ìˆ˜ë¬¸ì, ìˆ«ì, ë¶ˆí•„ìš”í•œ ê¸°í˜¸ëŠ” ì œê±°í•˜ì„¸ìš”
5. **ë¬¸ë§¥ ë¶„ì„**: ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ê°€ì¥ ì±… ì œëª©ë‹¤ìš´ ì¡°í•©ì„ ì°¾ìœ¼ì„¸ìš”
6. **ì¼ë°˜ì ì¸ ì±… ì œëª© íŒ¨í„´**: 
   - "~ì˜ ~" (ê²½í—˜ì˜ ë©¸ì¢…, ë§ˆìŒì˜ ê¸°ìˆ )
   - "~ë¡ " (ììœ ë¡ , ë¯¼ì£¼ì£¼ì˜ë¡ )
   - "~í•˜ë‹¤" (ì‹¯ë‹¤ë¥´íƒ€, ìœ„ë²„ë©˜ì‰¬)
   - ë‹¨ì¼ ë‹¨ì–´ (ë„¥ì„œìŠ¤, ììœ )

ğŸ” ì¶”ì¶œ ê³¼ì •:
1. í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì‹ë³„
2. ì±… ì œëª© íŒ¨í„´ì— ë§ëŠ” ì¡°í•©ì„ ì°¾ê¸°
3. ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ì™„ì„±ë„ ë†’ì€ ì œëª© ì„ íƒ
4. í™•ì‹ ì´ ì—†ìœ¼ë©´ "ì¶”ì •:" í‘œê¸°

âŒ í”¼í•´ì•¼ í•  ê²ƒë“¤:
- ì €ìëª…, ì¶œíŒì‚¬ëª…
- ë¶€ì œëª©ì´ë‚˜ ì„¤ëª…ë¬¸
- ë„ˆë¬´ ê¸´ ë¬¸ì¥
- ì˜ë¯¸ ì—†ëŠ” ì¡°í•©"""
            
            user_prompt = f"""ë‹¤ìŒì€ ì±… í‘œì§€ì—ì„œ OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ìœ„ì˜ ê·œì¹™ì„ ë”°ë¼ ê°€ì¥ ì±… ì œëª©ì¼ í™•ë¥ ì´ ë†’ì€ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ğŸ“– ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {text}

ğŸ’¡ íŒíŠ¸: 
- ë…¸ì´ì¦ˆê°€ ë§ì•„ë„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ë³´ì„¸ìš”
- í•œê¸€ê³¼ ì˜ì–´ê°€ ì„ì—¬ìˆìœ¼ë©´ í•œê¸€ì„ ìš°ì„ í•˜ì„¸ìš”
- ì±… ì œëª©ì€ ë³´í†µ ê°„ê²°í•˜ê³  ì˜ë¯¸ê°€ ëª…í™•í•©ë‹ˆë‹¤
- ì „ì²´ì ì¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¶”ë¡ í•˜ì„¸ìš”"""
            
            # ìƒˆë¡œìš´ GPT API í˜¸ì¶œ ë°©ì‹
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=300,
                temperature=0.1  # ë§¤ìš° ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
            )
            
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # ì‘ë‹µ ì¶”ì¶œ
            gpt_response = response.choices[0].message.content
            usage = response.usage
            
            # ì‘ë‹µ í›„ì²˜ë¦¬: "ì¶”ì •:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ì œëª©ë§Œ ì¶”ì¶œ
            cleaned_response = self._clean_book_title_response(gpt_response)
            
            return GPTResponse(
                original_text=text,
                prompt="ì±… ì œëª© ì¶”ì¶œ",
                gpt_response=cleaned_response,
                gpt_model=self.model,
                tokens_used=usage.total_tokens if usage else 0,
                response_time_ms=response_time_ms
            )
            
        except Exception as e:
            raise GPTException(f"ì±… ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def summarize_text(self, text: str) -> GPTResponse:
        """í…ìŠ¤íŠ¸ ìš”ì•½"""
        prompt = "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:"
        return await self.analyze_text(text, prompt)
    
    async def translate_text(self, text: str, target_language: str = "í•œêµ­ì–´") -> GPTResponse:
        """í…ìŠ¤íŠ¸ ë²ˆì—­"""
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {target_language}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”:"
        return await self.analyze_text(text, prompt)
    
    async def extract_keywords(self, text: str) -> GPTResponse:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        prompt = "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„):"
        return await self.analyze_text(text, prompt)
    
    async def answer_question(self, text: str, question: str) -> GPTResponse:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€"""
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\nì§ˆë¬¸: {question}"
        return await self.analyze_text(text, prompt)
    
    def _clean_book_title_response(self, response: str) -> str:
        """ì±… ì œëª© ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì‹¤ì œ ì œëª©ë§Œ ì¶”ì¶œ"""
        if not response:
            return ""
        
        # "ì¶”ì •:" ì œê±°
        if "ì¶”ì •:" in response:
            response = response.replace("ì¶”ì •:", "").strip()
        
        # "ì œëª©:" ì œê±°
        if "ì œëª©:" in response:
            response = response.replace("ì œëª©:", "").strip()
        
        # ë”°ì˜´í‘œ ì œê±°
        response = response.strip('"\'')
        
        # ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ê³µë°± ì •ë¦¬
        response = " ".join(response.split())
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±ë§Œ í—ˆìš©)
        # í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¸°ê³  ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì œê±°
        response = re.sub(r'[^\w\sê°€-í£]', '', response)
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
        response = re.sub(r'\s+', ' ', response).strip()
        
        return response
    
    async def batch_analyze(self, texts: list, prompt: str = "") -> list[GPTResponse]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¼ê´„ ë¶„ì„"""
        try:
            tasks = [self.analyze_text(text, prompt) for text in texts]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    processed_results.append(
                        GPTResponse(
                            original_text=texts[i],
                            prompt=prompt,
                            gpt_response=f"ì˜¤ë¥˜ ë°œìƒ: {str(result)}",
                            gpt_model=self.model,
                            tokens_used=0,
                            response_time_ms=0
                        )
                    )
                else:
                    processed_results.append(result)
            
            return processed_results
            
        except Exception as e:
            raise GPTException(f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_book_title_with_boxes(self, text_with_boxes: str) -> GPTResponse:
        """ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì±… ì œëª© ì¶”ì¶œ"""
        try:
            start_time = time.time()
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•œ ì±… ì œëª© ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ ì±… ì œëª© ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì±… ì œëª©ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

ğŸ“ **1ë‹¨ê³„: í…ìŠ¤íŠ¸ ë³´ì •**
ë¨¼ì € ê° í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë³´ì •í•˜ì„¸ìš”:
- OCR ì˜¤íƒ€ ìˆ˜ì • (ì˜ˆ: 'ì‡¼í¸í•˜ìš°ì–´' â†’ 'ì‡¼íœí•˜ìš°ì–´', 'ë§ˆí˜¼' â†’ 'ë§ˆí”')
- ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
- íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°)
- í•œê¸€/ì˜ì–´ í˜¼ìš© í…ìŠ¤íŠ¸ ì •ë¦¬
- ìˆ«ìì™€ ë¬¸ìì˜ í˜¼ë™ ìˆ˜ì • (ì˜ˆ: '0' â†’ 'O', '1' â†’ 'l')

ğŸ“š **2ë‹¨ê³„: ì±… ì œëª© ì¶”ì¶œ ê·œì¹™ (ìœ„ì¹˜ ì •ë³´ í™œìš©)**
1. **ìœ„ì¹˜ ìš°ì„ ìˆœìœ„**: 
   - ìƒë‹¨ ì¤‘ì•™ì— ìœ„ì¹˜í•œ í…ìŠ¤íŠ¸ê°€ ì±… ì œëª©ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
   - ì´ë¯¸ì§€ì˜ 1/3 ìƒë‹¨ ì˜ì—­ì— ìˆëŠ” í…ìŠ¤íŠ¸ ìš°ì„  ê³ ë ¤
2. **í¬ê¸°ì™€ ì‹ ë¢°ë„**: 
   - í° í°íŠ¸ í¬ê¸°(ë°”ìš´ë”© ë°•ìŠ¤ê°€ í°) í…ìŠ¤íŠ¸ ìš°ì„ 
   - ë†’ì€ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ìš°ì„ 
3. **ë°°ì¹˜ íŒ¨í„´**:
   - ì¤‘ì•™ ì •ë ¬ëœ í…ìŠ¤íŠ¸ê°€ ì œëª©ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
   - ì—¬ëŸ¬ ì¤„ë¡œ êµ¬ì„±ëœ ì œëª©ë„ ê³ ë ¤
4. **ì–¸ì–´ ìš°ì„ ìˆœìœ„**: í•œê¸€ > ì˜ì–´ > ê¸°íƒ€
5. **ê¸¸ì´ ê³ ë ¤**: ì±… ì œëª©ì€ ë³´í†µ 2-8ë‹¨ì–´ ì •ë„

ğŸ” **ë¶„ì„ ê³¼ì •**:
1. ê° í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë³´ì •
2. ìœ„ì¹˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒë‹¨ ì˜ì—­ í…ìŠ¤íŠ¸ ì‹ë³„
3. ì‹ ë¢°ë„ì™€ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ê³ ë ¤
4. ê°€ì¥ ì±… ì œëª©ë‹¤ìš´ ì¡°í•© ì„ íƒ
5. í™•ì‹ ì´ ì—†ìœ¼ë©´ "ì¶”ì •:" í‘œê¸°

âŒ **í”¼í•´ì•¼ í•  ê²ƒë“¤**:
- í•˜ë‹¨ì— ìœ„ì¹˜í•œ ì €ìëª…, ì¶œíŒì‚¬ëª…
- ì‘ì€ í°íŠ¸ì˜ ë¶€ê°€ ì •ë³´
- ë„ˆë¬´ ê¸´ ë¬¸ì¥
- ë³´ì • í›„ì—ë„ ì˜ë¯¸ ì—†ëŠ” í…ìŠ¤íŠ¸"""
            
            user_prompt = f"""ë‹¤ìŒì€ ì±… í‘œì§€ì—ì„œ OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ ì •ë³´ì…ë‹ˆë‹¤.
ìœ„ì¹˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ê°€ì¥ ì±… ì œëª©ì¼ í™•ë¥ ì´ ë†’ì€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ğŸ“– **ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ìœ„ì¹˜ ì •ë³´ í¬í•¨)**:
{text_with_boxes}

ğŸ’¡ **ë¶„ì„ ê°€ì´ë“œ**:
1. **í…ìŠ¤íŠ¸ ë³´ì •**: ê° í…ìŠ¤íŠ¸ì˜ OCR ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•˜ê³  ì •ë¦¬
2. **ìœ„ì¹˜ ë¶„ì„**: yê°’ì´ ì‘ì„ìˆ˜ë¡ ìƒë‹¨ì— ìœ„ì¹˜
3. **í¬ê¸° ë¶„ì„**: ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ê°€ í´ìˆ˜ë¡ ì¤‘ìš”í•œ í…ìŠ¤íŠ¸
4. **ì‹ ë¢°ë„**: ë†’ì€ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ìš°ì„  ê³ ë ¤

âš ï¸ **ì¤‘ìš”**: 
- ì„¤ëª…ì´ë‚˜ ë§ˆì»¤ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- "ì œëª©:", "ì¶”ì¶œ:", "ê²°ê³¼:" ë“±ì˜ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ë”°ì˜´í‘œë‚˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ìˆœìˆ˜í•œ ì±… ì œëª© í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”

ì˜ˆì‹œ:
âŒ ì˜ëª»ëœ ì‘ë‹µ: "ì œëª©: ë§ˆìŒì˜ ê¸°ìˆ "
âŒ ì˜ëª»ëœ ì‘ë‹µ: "ì¶”ì¶œëœ ì±… ì œëª©: 'ìš°ì—°í•œ ì¼ì€'"
âœ… ì˜¬ë°”ë¥¸ ì‘ë‹µ: "ë§ˆìŒì˜ ê¸°ìˆ "
âœ… ì˜¬ë°”ë¥¸ ì‘ë‹µ: "ìš°ì—°í•œ ì¼ì€"

ì±… ì œëª©:"""
            
            # GPT API í˜¸ì¶œ
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=400,  # í† í° ìˆ˜ ì¦ê°€ (ë³´ì • ë‹¨ê³„ ì¶”ê°€)
                temperature=0.1
            )
            
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # ì‘ë‹µ ì¶”ì¶œ
            gpt_response = response.choices[0].message.content
            usage = response.usage
            
            # ì‘ë‹µ í›„ì²˜ë¦¬ - ì±… ì œëª© ë¶€ë¶„ë§Œ ì¶”ì¶œ
            cleaned_response = self._extract_book_title_from_response(gpt_response)
            
            return GPTResponse(
                original_text=text_with_boxes,
                prompt="í…ìŠ¤íŠ¸ ë³´ì • ë° ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•œ ì±… ì œëª© ì¶”ì¶œ",
                gpt_response=cleaned_response,
                gpt_model=self.model,
                tokens_used=usage.total_tokens if usage else 0,
                response_time_ms=response_time_ms
            )
            
        except Exception as e:
            raise GPTException(f"ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•œ ì±… ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    def _extract_book_title_from_response(self, response: str) -> str:
        """GPT ì‘ë‹µì—ì„œ ìˆœìˆ˜í•œ ì±… ì œëª© í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
        if not response:
            return ""
        
        # ë‹¤ì–‘í•œ ë§ˆì»¤ íŒ¨í„´ ì œê±° (ë” í¬ê´„ì ìœ¼ë¡œ)
        markers_to_remove = [
            "ì¶”ì¶œëœ ì±… ì œëª©:",
            "ì±… ì œëª©:",
            "ì œëª©:",
            "**ì¶”ì¶œëœ ì±… ì œëª©**:",
            "**ì±… ì œëª©**:",
            "**ì œëª©**:",
            "ë³´ì •ëœ í…ìŠ¤íŠ¸:",
            "ë¶„ì„:",
            "ê²°ê³¼:",
            "ìµœì¢…:",
            "ì¶”ì •:",
            "ì¶”ì¶œ:",
            "ì„ íƒ:",
            "ê²°ë¡ :",
            "ğŸ“–",
            "ğŸ’¡",
            "âš ï¸",
            "âŒ",
            "âœ…",
            "title:",
            "Title:",
            "TITLE:",
            "ì±…ì œëª©:",
            "ì¶”ì¶œê²°ê³¼:",
            "ìµœì¢…ê²°ê³¼:"
        ]
        
        # ë§ˆì»¤ ì œê±°
        cleaned_response = response
        for marker in markers_to_remove:
            if marker in cleaned_response:
                # ë§ˆì»¤ ì´í›„ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                parts = cleaned_response.split(marker, 1)
                if len(parts) > 1:
                    cleaned_response = parts[1].strip()
        
        # ë”°ì˜´í‘œ ì œê±° (ëª¨ë“  ì¢…ë¥˜ì˜ ë”°ì˜´í‘œ)
        cleaned_response = cleaned_response.strip('"\'`""''')
        
        # ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ì²« ë²ˆì§¸ ì¤„ë§Œ ì¶”ì¶œ
        lines = cleaned_response.split('\n')
        for line in lines:
            line = line.strip()
            if line and not any(marker in line for marker in markers_to_remove):
                # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±ë§Œ í—ˆìš©)
                import re
                title = re.sub(r'[^\w\sê°€-í£]', '', line)
                title = re.sub(r'\s+', ' ', title).strip()
                
                if title:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ë°˜í™˜
                    return title
        
        # ë§ˆì»¤ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë§Œ ì œê±°
        import re
        final_title = re.sub(r'[^\w\sê°€-í£]', '', cleaned_response)
        final_title = re.sub(r'\s+', ' ', final_title).strip()
        
        return final_title 