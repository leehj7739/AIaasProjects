"""
OCR (Optical Character Recognition) ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ EasyOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ OCR ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- EasyOCR ì´ˆê¸°í™” ë° ì„¤ì •
- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë…¸ì´ì¦ˆ ì œê±°, ëŒ€ë¹„ í–¥ìƒ, ì´ì§„í™” ë“±)
- ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì²˜ë¦¬ (ì‘ì€ í…ìŠ¤íŠ¸ í¬ì°©)
- OCR ê²°ê³¼ í•„í„°ë§ ë° í›„ì²˜ë¦¬
- ë°•ì‹± ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ ë°•ìŠ¤ í‘œì‹œ)
- íŒŒì¼ ì—…ë¡œë“œ ë° ê²½ë¡œ ê¸°ë°˜ OCR ì§€ì›

ì „ì²˜ë¦¬ ê¸°ë²•:
1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
3. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
4. ìƒ¤í”„ë‹ í•„í„°
5. ëª¨í´ë¡œì§€ ì—°ì‚°
6. ì ì‘í˜• ì´ì§„í™”
7. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì²˜ë¦¬
"""

import easyocr
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
import os
import uuid
from typing import List, Tuple
from fastapi import UploadFile

from app.models.response import OCRResponse
from app.config.settings import settings
from app.core.exceptions import OCRException

class OCRService:
    """
    OCR ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    EasyOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ OCR ì„±ëŠ¥ì„ ìµœì í™”í•˜ê³ ,
    ê²°ê³¼ ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ í‘œì‹œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ì£¼ìš” ë©”ì„œë“œ:
    - extract_text(): íŒŒì¼ ì—…ë¡œë“œ ê¸°ë°˜ OCR
    - extract_text_from_path(): íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ OCR
    - extract_text_with_mode(): ëª¨ë“œì— ë”°ë¥¸ OCR (ìš´ì˜/í…ŒìŠ¤íŠ¸)
    """
    
    def __init__(self):
        """
        EasyOCR ë¦¬ë” ì´ˆê¸°í™”
        
        ì„¤ì •ëœ ì–¸ì–´(í•œêµ­ì–´, ì˜ì–´)ë¡œ EasyOCR ë¦¬ë”ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        GPU ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•œ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ CPU ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        try:
            print("ğŸ”§ EasyOCR ì´ˆê¸°í™” ì¤‘...")
            # EasyOCR ë¦¬ë” ì´ˆê¸°í™”
            # settings.OCR_LANGUAGES: ["ko", "en"] (í•œêµ­ì–´, ì˜ì–´)
            # gpu=False: CPU ì‚¬ìš© (GPUê°€ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ë™ì‘)
            # verbose=False: ë¡œê·¸ ì¶œë ¥ ìµœì†Œí™”
            self.reader = easyocr.Reader(
                settings.OCR_LANGUAGES,
                gpu=False,  # CPU ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
                verbose=False  # ë¡œê·¸ ì¤„ì´ê¸°
            )
            print("âœ… EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
            try:
                self.reader = easyocr.Reader(['ko', 'en'], gpu=False)
                print("âœ… ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e2:
                raise OCRException(f"EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e2)}")
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - OCR ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬ (ê°•ë„ ì¡°ì ˆ)
        
        OCR ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•©ë‹ˆë‹¤.
        ê°•ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ í…ìŠ¤íŠ¸ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        
        Args:
            image (np.ndarray): ì „ì²˜ë¦¬í•  ì´ë¯¸ì§€ (OpenCV í˜•ì‹)
            
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        try:
            print("ğŸ” ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            # ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {gray.shape}")
            
            # 2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬) - ë§¤ìš° ì•½í•œ ë¸”ëŸ¬
            # ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë˜ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´
            denoised = cv2.GaussianBlur(gray, (1, 1), 0)
            
            # 3. ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (CLAHE) - ëŒ€ë¹„ í–¥ìƒ (ì•½í•œ ê°•ë„)
            # ì´ë¯¸ì§€ì˜ ëŒ€ë¹„ë¥¼ í–¥ìƒì‹œì¼œ í…ìŠ¤íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(denoised)
            
            # 4. ìƒ¤í”„ë‹ í•„í„° ì ìš© (ì•½í•œ ê°•ë„)
            # í…ìŠ¤íŠ¸ì˜ ê²½ê³„ë¥¼ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦
            kernel_sharpen = np.array([[-0.5,-0.5,-0.5], [-0.5,5,-0.5], [-0.5,-0.5,-0.5]])
            sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)
            
            # 5. ëª¨í´ë¡œì§€ ì—°ì‚° (ìµœì†Œí•œì˜ ì ìš©)
            # í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì—°ê²°í•˜ê³  ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((1, 1), np.int32)
            morph = cv2.morphologyEx(sharpened, cv2.MORPH_CLOSE, kernel)
            
            # 6. ì ì‘í˜• ì´ì§„í™” (ë” ê´€ëŒ€í•œ ì„¤ì •)
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ë¥¼ ì´ì§„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            # ë¸”ë¡ í¬ê¸°ì™€ Cê°’ì„ ì¡°ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ì†ì‹¤ ìµœì†Œí™”
            binary = cv2.adaptiveThreshold(
                morph, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 15, 3  # ë¸”ë¡ í¬ê¸° ì¦ê°€, Cê°’ ì¦ê°€
            )
            
            # 7. ë…¸ì´ì¦ˆ ì œê±° (ìµœì†Œí•œì˜ ëª¨í´ë¡œì§€)
            # ì‘ì€ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë˜ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´
            kernel_clean = np.ones((1, 1), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_clean)
            
            print("âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return cleaned
            
        except Exception as e:
            print(f"âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©: {e}")
            return image
    
    def _preprocess_multiscale(self, image: np.ndarray) -> list:
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ - ì—¬ëŸ¬ í¬ê¸°ë¡œ ì²˜ë¦¬í•˜ì—¬ ì‘ì€ í…ìŠ¤íŠ¸ë„ í¬ì°© (ê°•ë„ ì¡°ì ˆ)"""
        try:
            preprocessed_images = []
            
            # ì›ë³¸ í¬ê¸° (ì•½í•œ ì „ì²˜ë¦¬)
            preprocessed_images.append(self._preprocess_image(image))
            
            # 1.2ë°° í™•ëŒ€ (ì•½í•œ ì „ì²˜ë¦¬)
            height, width = image.shape[:2]
            enlarged = cv2.resize(image, (int(width * 1.2), int(height * 1.2)), interpolation=cv2.INTER_LINEAR)
            preprocessed_images.append(self._preprocess_image(enlarged))
            
            # 1.5ë°° í™•ëŒ€ (ì•½í•œ ì „ì²˜ë¦¬)
            enlarged_15x = cv2.resize(image, (int(width * 1.5), int(height * 1.5)), interpolation=cv2.INTER_LINEAR)
            preprocessed_images.append(self._preprocess_image(enlarged_15x))
            
            return preprocessed_images
            
        except Exception as e:
            print(f"âš ï¸ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [self._preprocess_image(image)]
    
    def _enhance_small_text(self, image: np.ndarray) -> np.ndarray:
        """ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ (ì•½í•œ ê°•ë„)"""
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # 2. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ (ì•½í•œ ê°•ë„)
            gaussian = cv2.GaussianBlur(gray, (0, 0), 1.5)
            unsharp_mask = cv2.addWeighted(gray, 1.3, gaussian, -0.3, 0)
            
            # 3. ëŒ€ë¹„ ê°•í™” (ì•½í•œ ê°•ë„)
            clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
            enhanced = clahe.apply(unsharp_mask)
            
            # 4. ì´ì§„í™” (Otsu ë°©ë²• ì‚¬ìš©)
            _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            return binary
            
        except Exception as e:
            print(f"âš ï¸ ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _preprocess_original(self, image: np.ndarray) -> np.ndarray:
        """ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì „ì²˜ë¦¬ (ìµœì†Œí•œì˜ ì²˜ë¦¬)"""
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # 2. ë§¤ìš° ì•½í•œ ëŒ€ë¹„ í–¥ìƒ
            clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))
            enhanced = clahe.apply(gray)
            
            # 3. ì ì‘í˜• ì´ì§„í™” (ê´€ëŒ€í•œ ì„¤ì •)
            binary = cv2.adaptiveThreshold(
                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 21, 5
            )
            
            return binary
            
        except Exception as e:
            print(f"âš ï¸ ì›ë³¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _resize_image(self, image: np.ndarray, max_size: int = 1024) -> np.ndarray:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • - ë„ˆë¬´ í° ì´ë¯¸ì§€ ì²˜ë¦¬ ì†ë„ í–¥ìƒ"""
        height, width = image.shape[:2]
        
        if max(height, width) > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
            scale = max_size / max(height, width)
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}")
            return resized
        
        return image
    
    async def extract_text(self, file: UploadFile) -> OCRResponse:
        """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            print(f"ğŸ” OCR ì‹œì‘: {file.filename}")
            
            # íŒŒì¼ ì½ê¸°
            contents = await file.read()
            image = Image.open(io.BytesIO(contents))
            
            # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
            cv_image = self._resize_image(cv_image)
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¨¼ì € OCR ì‹œë„
            print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
            original_results = self.reader.readtext(cv_image)
            print(f"ğŸ“Š ì›ë³¸ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(original_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
            
            if original_results:
                for i, (bbox, text, conf) in enumerate(original_results[:3]):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                    print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
            
            # ì›ë³¸ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ ì‹œë„
            if not original_results:
                print("âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì‹œë„...")
                
                # ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë°©ë²• ì ìš©
                preprocessed_images = []
                
                # 1. ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì „ì²˜ë¦¬ (ìµœì†Œí•œì˜ ì²˜ë¦¬)
                print("ğŸ” ì›ë³¸ ê¸°ë°˜ ì „ì²˜ë¦¬ ì ìš©...")
                preprocessed_images.append(self._preprocess_original(cv_image))
                
                # 2. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì ìš© (ì•½í•œ ê°•ë„)
                print("ğŸ” ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì ìš©...")
                multiscale_images = self._preprocess_multiscale(cv_image)
                preprocessed_images.extend(multiscale_images)
                
                # 3. ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ë„ ì¶”ê°€ (ì•½í•œ ê°•ë„)
                print("ğŸ” ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ ì ìš©...")
                small_text_enhanced = self._enhance_small_text(cv_image)
                preprocessed_images.append(small_text_enhanced)
                
                # 4. ì›ë³¸ ì´ë¯¸ì§€ë„ ì§ì ‘ ì‚¬ìš© (ì „ì²˜ë¦¬ ì—†ì´)
                print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ ì§ì ‘ ì‚¬ìš©...")
                preprocessed_images.append(cv_image)
                
                # ëª¨ë“  ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
                all_results = []
                for i, preprocessed_image in enumerate(preprocessed_images):
                    print(f"ğŸ” ì „ì²˜ë¦¬ ì´ë¯¸ì§€ {i+1}/{len(preprocessed_images)}ì—ì„œ OCR ìˆ˜í–‰...")
                    try:
                        results = self.reader.readtext(preprocessed_image)
                        print(f"  â†’ {len(results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
                        all_results.extend(results)
                    except Exception as e:
                        print(f"  â†’ OCR ì‹¤íŒ¨: {e}")
                
                # ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
                unique_results = self._filter_and_merge_results(all_results)
                final_results = unique_results
            else:
                final_results = original_results
            
            # ê²°ê³¼ ì²˜ë¦¬
            extracted_text = []
            bounding_boxes = []
            
            for (bbox, text, confidence) in final_results:
                extracted_text.append(text)
                # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                converted_bbox = [[float(x), float(y)] for x, y in bbox]
                bounding_boxes.append(converted_bbox)
            
            print(f"ğŸ“Š ìµœì¢… OCR ê²°ê³¼: {len(extracted_text)}ê°œ í…ìŠ¤íŠ¸")
            if extracted_text:
                print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {' '.join(extracted_text[:3])}...")
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ì›ë³¸ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ)
            result_image = self._create_result_image(cv_image, final_results)
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            filename = f"{uuid.uuid4()}.jpg"
            result_path = os.path.join(settings.RESULTS_DIR, filename)
            cv2.imwrite(result_path, result_image)

            # ê²°ê³¼ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ ì œí•œ (20ê°œ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ)
            try:
                files = [os.path.join(settings.RESULTS_DIR, f) for f in os.listdir(settings.RESULTS_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                if len(files) > 20:
                    files.sort(key=lambda x: os.path.getctime(x))  # ìƒì„±ì‹œê°„ ê¸°ì¤€ ì •ë ¬
                    for old_file in files[:-20]:
                        try:
                            os.remove(old_file)
                            print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ê²°ê³¼ ì´ë¯¸ì§€ ì‚­ì œ: {old_file}")
                        except Exception as e:
                            print(f"âš ï¸ ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨: {old_file} - {e}")
            except Exception as e:
                print(f"âš ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            return OCRResponse(
                original_filename=file.filename,
                extracted_text=" ".join(extracted_text),
                confidence_scores=[float(conf) for _, _, conf in final_results],
                bounding_boxes=bounding_boxes,
                result_image_url=f"/static/results/{filename}",
                total_text_count=len(extracted_text)
            )
            
        except Exception as e:
            print(f"âŒ OCR ì‹¤íŒ¨: {e}")
            raise OCRException(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    def _filter_and_merge_results(self, all_results: list) -> list:
        """OCR ê²°ê³¼ ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§"""
        try:
            # í…ìŠ¤íŠ¸ë³„ë¡œ ê·¸ë£¹í™”
            text_groups = {}
            for bbox, text, confidence in all_results:
                # í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
                normalized_text = text.strip().lower()
                
                if normalized_text not in text_groups:
                    text_groups[normalized_text] = []
                
                text_groups[normalized_text].append((bbox, text, confidence))
            
            # ê° ê·¸ë£¹ì—ì„œ ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼ ì„ íƒ
            filtered_results = []
            for normalized_text, group in text_groups.items():
                # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                group.sort(key=lambda x: x[2], reverse=True)
                best_result = group[0]
                
                # ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš© (ë„ˆë¬´ ë‚®ì€ ì‹ ë¢°ë„ ì œê±°)
                if best_result[2] > 0.1:  # 10% ì´ìƒ ì‹ ë¢°ë„
                    filtered_results.append(best_result)
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            filtered_results.sort(key=lambda x: x[2], reverse=True)
            
            print(f"ğŸ“Š OCR ê²°ê³¼ í•„í„°ë§: {len(all_results)} â†’ {len(filtered_results)}")
            return filtered_results
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ í•„í„°ë§ ì‹¤íŒ¨: {e}")
            return all_results
    
    def _create_result_image(self, image: np.ndarray, results: List[Tuple]) -> np.ndarray:
        """ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ ë°•ìŠ¤ í‘œì‹œ) - í•œê¸€ ì§€ì›"""
        # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(image_rgb)
        draw = ImageDraw.Draw(pil_image)
        
        # í°íŠ¸ ì„¤ì • (í•œê¸€ í°íŠ¸ ìš°ì„  ì‹œë„)
        font = None
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",  # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/gulim.ttc",   # êµ´ë¦¼
            "C:/Windows/Fonts/batang.ttc",  # ë°”íƒ•
            "C:/Windows/Fonts/dotum.ttc",   # ë‹ì›€
            "arial.ttf",                    # Arial
            "malgun.ttf"                    # ë§‘ì€ ê³ ë”• (ìƒëŒ€ ê²½ë¡œ)
        ]
        
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, 20)
                print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
                break
            except Exception as e:
                print(f"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")
                continue
        
        if font is None:
            print("âš ï¸ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
            font = ImageFont.load_default()
        
        for (bbox, text, confidence) in results:
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            pts = np.array(bbox, np.int32)
            
            # PIL ì´ë¯¸ì§€ì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw.polygon([tuple(point) for point in pts], outline=(0, 255, 0), width=2)
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚°
            x, y = bbox[0]
            text_x, text_y = int(x), int(y) - 25
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
            try:
                bbox_text = draw.textbbox((text_x, text_y), text, font=font)
                draw.rectangle(bbox_text, fill=(0, 0, 0))
                draw.text((text_x, text_y), text, fill=(0, 255, 0), font=font)
            except Exception as e:
                print(f"âš ï¸ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
                # í°íŠ¸ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
                draw.text((text_x, text_y), text, fill=(0, 255, 0))
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        return result_image
    
    async def extract_text_from_path(self, image_path: str) -> OCRResponse:
        """íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            print(f"ğŸ” íŒŒì¼ ê²½ë¡œ OCR ì‹œì‘: {image_path}")
            
            image = cv2.imread(image_path)
            if image is None:
                raise OCRException("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            image = self._resize_image(image)
            print(f"ğŸ“ ë¦¬ì‚¬ì´ì¦ˆ í›„ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¨¼ì € OCR ì‹œë„
            print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
            original_results = self.reader.readtext(image)
            print(f"ğŸ“Š ì›ë³¸ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(original_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
            
            if original_results:
                for i, (bbox, text, conf) in enumerate(original_results[:3]):
                    print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
            
            # ì›ë³¸ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ ì‹œë„
            if not original_results:
                print("âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì‹œë„...")
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                preprocessed_image = self._preprocess_image(image)
                print("ğŸ” ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
                
                preprocessed_results = self.reader.readtext(preprocessed_image)
                print(f"ğŸ“Š ì „ì²˜ë¦¬ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(preprocessed_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
                
                if preprocessed_results:
                    for i, (bbox, text, conf) in enumerate(preprocessed_results[:3]):
                        print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
                
                results = preprocessed_results if preprocessed_results else original_results
            else:
                results = original_results
            
            extracted_text = []
            bounding_boxes = []
            
            for (bbox, text, confidence) in results:
                extracted_text.append(text)
                # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                converted_bbox = [[float(x), float(y)] for x, y in bbox]
                bounding_boxes.append(converted_bbox)
            
            print(f"ğŸ“Š ìµœì¢… OCR ê²°ê³¼: {len(extracted_text)}ê°œ í…ìŠ¤íŠ¸")
            if extracted_text:
                print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {' '.join(extracted_text)}")
            
            return OCRResponse(
                original_filename=os.path.basename(image_path),
                extracted_text=" ".join(extracted_text),
                confidence_scores=[float(conf) for _, _, conf in results],
                bounding_boxes=bounding_boxes,
                result_image_url="",
                total_text_count=len(extracted_text)
            )
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ê²½ë¡œ OCR ì‹¤íŒ¨: {e}")
            raise OCRException(f"íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_text_with_mode(self, file: UploadFile = None, image_path: str = None, mode: str = "prod"):
        """
        modeì— ë”°ë¼ ì—…ë¡œë“œ íŒŒì¼ ë˜ëŠ” ê²½ë¡œ ê¸°ë°˜ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
        """
        if mode == "test" and image_path:
            # ê²½ë¡œ ê¸°ë°˜ OCR (í…ŒìŠ¤íŠ¸ìš©)
            return await self.extract_text_from_path(image_path)
        elif file:
            # ì—…ë¡œë“œ íŒŒì¼ OCR (ìš´ì˜ìš©)
            return await self.extract_text(file)
        else:
            raise OCRException("íŒŒì¼ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.") 