"""
OCR (Optical Character Recognition) ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ EasyOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ OCR ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- EasyOCR ì´ˆê¸°í™” ë° ì„¤ì •
- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë…¸ì´ì¦ˆ ì œê±°, ëŒ€ë¹„ í–¥ìƒ, ì´ì§„í™” ë“±)
- ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì²˜ë¦¬ (ì‘ì€ í…ìŠ¤íŠ¸ í¬ì°©)
- OCR ê²°ê³¼ í•„í„°ë§ ë° í›„ì²˜ë¦¬
- ë°•ì‹± ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ ë°•ìŠ¤ í‘œì‹œ)
- íŒŒì¼ ì—…ë¡œë“œ ë° ê²½ë¡œ ê¸°ë°˜ OCR ì§€ì›

ì „ì²˜ë¦¬ ê¸°ë²•:
1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
3. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
4. ìƒ¤í”„ë‹ í•„í„°
5. ëª¨í´ë¡œì§€ ì—°ì‚°
6. ì ì‘í˜• ì´ì§„í™”
7. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì²˜ë¦¬
"""

import easyocr
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
import os
import uuid
from typing import List, Tuple
from fastapi import UploadFile
import time
import re

from app.models.response import OCRResponse
from app.config.settings import settings
from app.core.exceptions import OCRException

class OCRService:
    """
    OCR ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    EasyOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ OCR ì„±ëŠ¥ì„ ìµœì í™”í•˜ê³ ,
    ê²°ê³¼ ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ í‘œì‹œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ì£¼ìš” ë©”ì„œë“œ:
    - extract_text(): íŒŒì¼ ì—…ë¡œë“œ ê¸°ë°˜ OCR
    - extract_text_from_path(): íŒŒì¼ ê²½ë¡œ ê¸°ë°˜ OCR
    - extract_text_with_mode(): ëª¨ë“œì— ë”°ë¥¸ OCR (ìš´ì˜/í…ŒìŠ¤íŠ¸)
    """
    
    def __init__(self):
        """
        EasyOCR ë¦¬ë” ì´ˆê¸°í™”
        
        ì„¤ì •ëœ ì–¸ì–´(í•œêµ­ì–´, ì˜ì–´)ë¡œ EasyOCR ë¦¬ë”ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        GPU ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•œ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ CPU ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        try:
            print("ğŸ”§ EasyOCR ì´ˆê¸°í™” ì¤‘...")
            # EasyOCR ë¦¬ë” ì´ˆê¸°í™”
            # settings.OCR_LANGUAGES: ["ko", "en"] (í•œêµ­ì–´, ì˜ì–´)
            # gpu=False: CPU ì‚¬ìš© (GPUê°€ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ë™ì‘)
            # verbose=False: ë¡œê·¸ ì¶œë ¥ ìµœì†Œí™”
            self.reader = easyocr.Reader(
                settings.OCR_LANGUAGES,
                gpu=False,  # CPU ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
                verbose=False  # ë¡œê·¸ ì¤„ì´ê¸°
            )
            print("âœ… EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
            try:
                self.reader = easyocr.Reader(['ko', 'en'], gpu=False)
                print("âœ… ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e2:
                raise OCRException(f"EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e2)}")
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - OCR ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬ (ê°•ë„ ì¡°ì ˆ)
        
        OCR ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ë²•ì„ ì ìš©í•©ë‹ˆë‹¤.
        ê°•ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ í…ìŠ¤íŠ¸ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        
        Args:
            image (np.ndarray): ì „ì²˜ë¦¬í•  ì´ë¯¸ì§€ (OpenCV í˜•ì‹)
            
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        try:
            print("ğŸ” ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            # ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {gray.shape}")
            
            # 2. ë…¸ì´ì¦ˆ ì œê±° (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬) - ë§¤ìš° ì•½í•œ ë¸”ëŸ¬
            # ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë˜ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´
            denoised = cv2.GaussianBlur(gray, (1, 1), 0)
            
            # 3. ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (CLAHE) - ëŒ€ë¹„ í–¥ìƒ (ì•½í•œ ê°•ë„)
            # ì´ë¯¸ì§€ì˜ ëŒ€ë¹„ë¥¼ í–¥ìƒì‹œì¼œ í…ìŠ¤íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(denoised)
            
            # 4. ìƒ¤í”„ë‹ í•„í„° ì ìš© (ì•½í•œ ê°•ë„)
            # í…ìŠ¤íŠ¸ì˜ ê²½ê³„ë¥¼ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦
            kernel_sharpen = np.array([[-0.5,-0.5,-0.5], [-0.5,5,-0.5], [-0.5,-0.5,-0.5]])
            sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)
            
            # 5. ëª¨í´ë¡œì§€ ì—°ì‚° (ìµœì†Œí•œì˜ ì ìš©)
            # í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì—°ê²°í•˜ê³  ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((1, 1), np.int32)
            morph = cv2.morphologyEx(sharpened, cv2.MORPH_CLOSE, kernel)
            
            # 6. ì ì‘í˜• ì´ì§„í™” (ë” ê´€ëŒ€í•œ ì„¤ì •)
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ë¥¼ ì´ì§„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            # ë¸”ë¡ í¬ê¸°ì™€ Cê°’ì„ ì¡°ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ì†ì‹¤ ìµœì†Œí™”
            binary = cv2.adaptiveThreshold(
                morph, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 15, 3  # ë¸”ë¡ í¬ê¸° ì¦ê°€, Cê°’ ì¦ê°€
            )
            
            # 7. ë…¸ì´ì¦ˆ ì œê±° (ìµœì†Œí•œì˜ ëª¨í´ë¡œì§€)
            # ì‘ì€ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë˜ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´
            kernel_clean = np.ones((1, 1), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_clean)
            
            print("âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return cleaned
            
        except Exception as e:
            print(f"âš ï¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©: {e}")
            return image
    
    def _preprocess_multiscale(self, image: np.ndarray) -> list:
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ - ì—¬ëŸ¬ í¬ê¸°ë¡œ ì²˜ë¦¬í•˜ì—¬ ì‘ì€ í…ìŠ¤íŠ¸ë„ í¬ì°© (ê°•ë„ ì¡°ì ˆ)"""
        try:
            preprocessed_images = []
            
            # ì›ë³¸ í¬ê¸° (ì•½í•œ ì „ì²˜ë¦¬)
            preprocessed_images.append(self._preprocess_image(image))
            
            # 1.2ë°° í™•ëŒ€ (ì•½í•œ ì „ì²˜ë¦¬)
            height, width = image.shape[:2]
            enlarged = cv2.resize(image, (int(width * 1.2), int(height * 1.2)), interpolation=cv2.INTER_LINEAR)
            preprocessed_images.append(self._preprocess_image(enlarged))
            
            # 1.5ë°° í™•ëŒ€ (ì•½í•œ ì „ì²˜ë¦¬)
            enlarged_15x = cv2.resize(image, (int(width * 1.5), int(height * 1.5)), interpolation=cv2.INTER_LINEAR)
            preprocessed_images.append(self._preprocess_image(enlarged_15x))
            
            return preprocessed_images
            
        except Exception as e:
            print(f"âš ï¸ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [self._preprocess_image(image)]
    
    def _enhance_small_text(self, image: np.ndarray) -> np.ndarray:
        """ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ (ì•½í•œ ê°•ë„)"""
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # 2. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ (ì•½í•œ ê°•ë„)
            gaussian = cv2.GaussianBlur(gray, (0, 0), 1.5)
            unsharp_mask = cv2.addWeighted(gray, 1.3, gaussian, -0.3, 0)
            
            # 3. ëŒ€ë¹„ ê°•í™” (ì•½í•œ ê°•ë„)
            clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
            enhanced = clahe.apply(unsharp_mask)
            
            # 4. ì´ì§„í™” (Otsu ë°©ë²• ì‚¬ìš©)
            _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            return binary
            
        except Exception as e:
            print(f"âš ï¸ ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _preprocess_original(self, image: np.ndarray) -> np.ndarray:
        """ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì „ì²˜ë¦¬ (ìµœì†Œí•œì˜ ì²˜ë¦¬)"""
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # 2. ë§¤ìš° ì•½í•œ ëŒ€ë¹„ í–¥ìƒ
            clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))
            enhanced = clahe.apply(gray)
            
            # 3. ì ì‘í˜• ì´ì§„í™” (ê´€ëŒ€í•œ ì„¤ì •)
            binary = cv2.adaptiveThreshold(
                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 21, 5
            )
            
            return binary
            
        except Exception as e:
            print(f"âš ï¸ ì›ë³¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _resize_image(self, image: np.ndarray, max_size: int = 1024) -> np.ndarray:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • - ë„ˆë¬´ í° ì´ë¯¸ì§€ ì²˜ë¦¬ ì†ë„ í–¥ìƒ"""
        height, width = image.shape[:2]
        
        if max(height, width) > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
            scale = max_size / max(height, width)
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}")
            return resized
        
        return image
    
    async def _perform_ocr(self, image: np.ndarray) -> list:
        """
        ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
        
        Args:
            image (np.ndarray): OCR ì²˜ë¦¬í•  ì´ë¯¸ì§€
            
        Returns:
            list: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            print("ğŸ” OCR ì²˜ë¦¬ ì‹œì‘...")
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¨¼ì € OCR ì‹œë„
            print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
            original_results = self.reader.readtext(image)
            print(f"ğŸ“Š ì›ë³¸ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(original_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
            
            if original_results:
                for i, (bbox, text, conf) in enumerate(original_results[:3]):
                    print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
                return original_results
            
            # ì›ë³¸ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ ì‹œë„
            print("âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì‹œë„...")
            
            # ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë°©ë²• ì ìš©
            preprocessed_images = []
            
            # 1. ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì „ì²˜ë¦¬ (ìµœì†Œí•œì˜ ì²˜ë¦¬)
            print("ğŸ” ì›ë³¸ ê¸°ë°˜ ì „ì²˜ë¦¬ ì ìš©...")
            preprocessed_images.append(self._preprocess_original(image))
            
            # 2. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì ìš© (ì•½í•œ ê°•ë„)
            print("ğŸ” ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì „ì²˜ë¦¬ ì ìš©...")
            multiscale_images = self._preprocess_multiscale(image)
            preprocessed_images.extend(multiscale_images)
            
            # 3. ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ë„ ì¶”ê°€ (ì•½í•œ ê°•ë„)
            print("ğŸ” ì‘ì€ í…ìŠ¤íŠ¸ ê°•í™” ì „ì²˜ë¦¬ ì ìš©...")
            small_text_enhanced = self._enhance_small_text(image)
            preprocessed_images.append(small_text_enhanced)
            
            # 4. ì›ë³¸ ì´ë¯¸ì§€ë„ ì§ì ‘ ì‚¬ìš© (ì „ì²˜ë¦¬ ì—†ì´)
            print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ ì§ì ‘ ì‚¬ìš©...")
            preprocessed_images.append(image)
            
            # ëª¨ë“  ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
            all_results = []
            for i, preprocessed_image in enumerate(preprocessed_images):
                print(f"ğŸ” ì „ì²˜ë¦¬ ì´ë¯¸ì§€ {i+1}/{len(preprocessed_images)}ì—ì„œ OCR ìˆ˜í–‰...")
                try:
                    results = self.reader.readtext(preprocessed_image)
                    print(f"  â†’ {len(results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
                    all_results.extend(results)
                except Exception as e:
                    print(f"  â†’ OCR ì‹¤íŒ¨: {e}")
            
            return all_results
            
        except Exception as e:
            print(f"âŒ OCR ìˆ˜í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _save_result_image(self, result_image: np.ndarray, original_filename: str) -> str:
        """
        ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        
        Args:
            result_image (np.ndarray): ì €ì¥í•  ê²°ê³¼ ì´ë¯¸ì§€
            original_filename (str): ì›ë³¸ íŒŒì¼ëª…
            
        Returns:
            str: ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ
        """
        try:
            # íŒŒì¼ëª… ìƒì„±
            filename = f"{uuid.uuid4()}.jpg"
            result_path = os.path.join(settings.RESULTS_DIR, filename)
            
            # ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(result_path, result_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {result_path}")
            
            # ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ ì ìš© (20ê°œ ìœ ì§€)
            await self._limit_result_images()
            
            return filename
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    async def _limit_result_images(self):
        """ê²°ê³¼ ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ 20ê°œë¡œ ì œí•œí•˜ê³  ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì‚­ì œ"""
        try:
            # ê²°ê³¼ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            files = [f for f in os.listdir(settings.RESULTS_DIR) 
                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            
            # 20ê°œë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
            if len(files) > settings.MAX_RESULT_IMAGES:
                # íŒŒì¼ ê²½ë¡œì™€ ìƒì„± ì‹œê°„ì„ í•¨ê»˜ ì €ì¥
                file_times = []
                for filename in files:
                    file_path = os.path.join(settings.RESULTS_DIR, filename)
                    if os.path.exists(file_path):
                        creation_time = os.path.getctime(file_path)
                        file_times.append((file_path, creation_time))
                
                # ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
                file_times.sort(key=lambda x: x[1])
                
                # ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ë“¤ ì‚­ì œ (20ê°œ ì´ˆê³¼ë¶„ë§Œ)
                files_to_delete = file_times[:-settings.MAX_RESULT_IMAGES]
                
                for file_path, _ in files_to_delete:
                    try:
                        os.remove(file_path)
                        print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ê²°ê³¼ ì´ë¯¸ì§€ ì‚­ì œ: {os.path.basename(file_path)}")
                    except Exception as e:
                        print(f"âš ï¸ ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {e}")
                
                print(f"âœ… ê²°ê³¼ ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ ì ìš©: {len(files)} â†’ {settings.MAX_RESULT_IMAGES}")
                        
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _convert_results_to_python(self, results):
        """OCR ê²°ê³¼ì˜ numpy íƒ€ì…ì„ íŒŒì´ì¬ ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        converted = []
        for bbox, text, confidence in results:
            bbox_py = [[float(x), float(y)] for x, y in bbox]
            converted.append((bbox_py, str(text), float(confidence)))
        return converted

    async def extract_text(self, file: UploadFile) -> OCRResponse:
        """
        íŒŒì¼ ì—…ë¡œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            file (UploadFile): ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼
            
        Returns:
            OCRResponse: OCR ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            print(f"ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename}")
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            file_content = await file.read()
            image_array = np.frombuffer(file_content, np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
            
            if image is None:
                raise OCRException("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ë„ˆë¬´ í° ì´ë¯¸ì§€ ì²˜ë¦¬)
            image = self._resize_image(image)
            
            # OCR ì²˜ë¦¬
            results = await self._perform_ocr(image)
            
            # ê²°ê³¼ í•„í„°ë§ ë° ë³‘í•©
            filtered_results = self._filter_and_merge_results(results)
            
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒì„±
            extracted_text = "\n".join([result[1] for result in filtered_results])
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ì„¤ì •ì— ë”°ë¼ ì €ì¥)
            result_image_path = None
            if settings.SAVE_RESULT_IMAGES:
                result_image = self._create_result_image(image, filtered_results)
                result_image_path = await self._save_result_image(result_image, file.filename)
            
            print(f"âœ… OCR ì²˜ë¦¬ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text)}")
            
            return OCRResponse(
                extracted_text=extracted_text,
                confidence_scores=[float(result[2]) for result in filtered_results],
                processing_time_ms=processing_time_ms,
                result_image_path=result_image_path,
                text_boxes=self._convert_results_to_python(filtered_results)
            )
            
        except Exception as e:
            print(f"âŒ OCR ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise OCRException(f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _filter_and_merge_results(self, all_results: list) -> list:
        """OCR ê²°ê³¼ ì¤‘ë³µ ì œê±° ë° ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§"""
        try:
            # í…ìŠ¤íŠ¸ë³„ë¡œ ê·¸ë£¹í™”
            text_groups = {}
            for bbox, text, confidence in all_results:
                # í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
                normalized_text = text.strip().lower()
                
                if normalized_text not in text_groups:
                    text_groups[normalized_text] = []
                
                text_groups[normalized_text].append((bbox, text, confidence))
            
            # ê° ê·¸ë£¹ì—ì„œ ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼ ì„ íƒ
            filtered_results = []
            for normalized_text, group in text_groups.items():
                # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                group.sort(key=lambda x: x[2], reverse=True)
                best_result = group[0]
                
                # ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš© (ë„ˆë¬´ ë‚®ì€ ì‹ ë¢°ë„ ì œê±°)
                if best_result[2] > 0.1:  # 10% ì´ìƒ ì‹ ë¢°ë„
                    filtered_results.append(best_result)
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            filtered_results.sort(key=lambda x: x[2], reverse=True)
            
            print(f"ğŸ“Š OCR ê²°ê³¼ í•„í„°ë§: {len(all_results)} â†’ {len(filtered_results)}")
            return filtered_results
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ í•„í„°ë§ ì‹¤íŒ¨: {e}")
            return all_results
    
    def _create_result_image(self, image: np.ndarray, results: List[Tuple]) -> np.ndarray:
        """ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ ë°•ìŠ¤ í‘œì‹œ) - í•œê¸€ ì§€ì›"""
        # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(image_rgb)
        draw = ImageDraw.Draw(pil_image)
        
        # í°íŠ¸ ì„¤ì • (í•œê¸€ í°íŠ¸ ìš°ì„  ì‹œë„)
        font = None
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",  # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/gulim.ttc",   # êµ´ë¦¼
            "C:/Windows/Fonts/batang.ttc",  # ë°”íƒ•
            "C:/Windows/Fonts/dotum.ttc",   # ë‹ì›€
            "arial.ttf",                    # Arial
            "malgun.ttf"                    # ë§‘ì€ ê³ ë”• (ìƒëŒ€ ê²½ë¡œ)
        ]
        
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, 20)
                print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
                break
            except Exception as e:
                print(f"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_path} - {e}")
                continue
        
        if font is None:
            print("âš ï¸ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
            font = ImageFont.load_default()
        
        for (bbox, text, confidence) in results:
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            pts = np.array(bbox, np.int32)
            
            # PIL ì´ë¯¸ì§€ì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw.polygon([tuple(point) for point in pts], outline=(0, 255, 0), width=2)
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚°
            x, y = bbox[0]
            text_x, text_y = int(x), int(y) - 25
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í–¥ìƒ)
            try:
                bbox_text = draw.textbbox((text_x, text_y), text, font=font)
                draw.rectangle(bbox_text, fill=(0, 0, 0))
                draw.text((text_x, text_y), text, fill=(0, 255, 0), font=font)
            except Exception as e:
                print(f"âš ï¸ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
                # í°íŠ¸ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
                draw.text((text_x, text_y), text, fill=(0, 255, 0))
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        result_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        return result_image
    
    async def extract_text_from_path(self, image_path: str) -> OCRResponse:
        """íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            print(f"ğŸ” íŒŒì¼ ê²½ë¡œ OCR ì‹œì‘: {image_path}")
            
            image = cv2.imread(image_path)
            if image is None:
                raise OCRException("ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            image = self._resize_image(image)
            print(f"ğŸ“ ë¦¬ì‚¬ì´ì¦ˆ í›„ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë¨¼ì € OCR ì‹œë„
            print("ğŸ” ì›ë³¸ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
            original_results = self.reader.readtext(image)
            print(f"ğŸ“Š ì›ë³¸ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(original_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
            
            if original_results:
                for i, (bbox, text, conf) in enumerate(original_results[:3]):
                    print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
            
            # ì›ë³¸ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ ì‹œë„
            if not original_results:
                print("âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì‹œë„...")
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                preprocessed_image = self._preprocess_image(image)
                print("ğŸ” ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
                
                preprocessed_results = self.reader.readtext(preprocessed_image)
                print(f"ğŸ“Š ì „ì²˜ë¦¬ ì´ë¯¸ì§€ OCR ê²°ê³¼: {len(preprocessed_results)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬")
                
                if preprocessed_results:
                    for i, (bbox, text, conf) in enumerate(preprocessed_results[:3]):
                        print(f"  {i+1}. '{text}' (ì‹ ë¢°ë„: {conf:.2f})")
                
                results = preprocessed_results if preprocessed_results else original_results
            else:
                results = original_results
            
            extracted_text = []
            bounding_boxes = []
            
            for (bbox, text, confidence) in results:
                extracted_text.append(text)
                # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                converted_bbox = [[float(x), float(y)] for x, y in bbox]
                bounding_boxes.append(converted_bbox)
            
            print(f"ğŸ“Š ìµœì¢… OCR ê²°ê³¼: {len(extracted_text)}ê°œ í…ìŠ¤íŠ¸")
            if extracted_text:
                print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {' '.join(extracted_text)}")
            
            return OCRResponse(
                extracted_text=" ".join(extracted_text),
                confidence_scores=[float(conf) for _, _, conf in results],
                processing_time_ms=None,
                result_image_path=None,
                text_boxes=self._convert_results_to_python(results)
            )
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ê²½ë¡œ OCR ì‹¤íŒ¨: {e}")
            raise OCRException(f"íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_text_with_mode(self, file: UploadFile = None, image_path: str = None, mode: str = "prod"):
        """
        modeì— ë”°ë¼ ì—…ë¡œë“œ íŒŒì¼ ë˜ëŠ” ê²½ë¡œ ê¸°ë°˜ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
        """
        if mode == "test" and image_path:
            # ê²½ë¡œ ê¸°ë°˜ OCR (í…ŒìŠ¤íŠ¸ìš©)
            return await self.extract_text_from_path(image_path)
        elif file:
            # ì—…ë¡œë“œ íŒŒì¼ OCR (ìš´ì˜ìš©)
            return await self.extract_text(file)
        else:
            raise OCRException("íŒŒì¼ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬"""
        # í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±ë§Œ í—ˆìš©
        cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text)
        
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        cleaned = cleaned.strip()
        
        return cleaned

    def _format_text_with_boxes(self, text_boxes):
        """í…ìŠ¤íŠ¸ì™€ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ í•¨ê»˜ í¬ë§·íŒ…"""
        if not text_boxes:
            return ""
        
        formatted_lines = []
        for i, (bbox, text, confidence) in enumerate(text_boxes):
            # í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            cleaned_text = self._clean_text(text)
            
            # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
            if not cleaned_text:
                continue
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
            x_coords = [point[0] for point in bbox]
            y_coords = [point[1] for point in bbox]
            
            # ìœ„ì¹˜ ì •ë³´ ê³„ì‚°
            left = min(x_coords)
            top = min(y_coords)
            right = max(x_coords)
            bottom = max(y_coords)
            
            # í…ìŠ¤íŠ¸ì™€ ìœ„ì¹˜ ì •ë³´ë¥¼ í•¨ê»˜ í¬ë§·íŒ…
            line = f"[{i+1}] í…ìŠ¤íŠ¸: '{cleaned_text}' | ìœ„ì¹˜: ({left:.0f}, {top:.0f}) ~ ({right:.0f}, {bottom:.0f}) | ì‹ ë¢°ë„: {confidence:.2f}"
            formatted_lines.append(line)
        
        return "\n".join(formatted_lines) 