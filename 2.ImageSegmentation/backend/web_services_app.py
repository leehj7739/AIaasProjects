#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì›¹ ê¸°ë°˜ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„œë¹„ìŠ¤
ë‹¤ì–‘í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

from flask import Flask, request, jsonify, render_template, send_file
from ultralytics import YOLO
import cv2
import numpy as np
import os
import base64
import json
import torch
import requests
from urllib.parse import urlparse
import mediapipe as mp
from PIL import Image, ImageFilter, ImageEnhance
from pathlib import Path
import imageio

# PyTorch 2.6 í˜¸í™˜ì„± ì„¤ì •
torch.serialization.add_safe_globals(['ultralytics.nn.tasks.SegmentationModel'])

app = Flask(__name__)

# ëª¨ë¸ ì´ˆê¸°í™”
yolo_model = YOLO('yolov8n-seg.pt')
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5
)

# í´ë” ìƒì„±
UPLOAD_FOLDER = 'uploads'
RESULTS_FOLDER = 'results'
if not os.path.exists(RESULTS_FOLDER):
    os.makedirs(RESULTS_FOLDER)
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

def remove_duplicates(boxes, masks, confidences, classes, iou_threshold=0.5):
    """ì¤‘ë³µ ê°ì²´ ì œê±° (Non-Maximum Suppression) - í´ë˜ìŠ¤ë³„ë¡œ ìˆ˜í–‰"""
    if len(boxes) == 0:
        return [], [], [], []
    
    # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
    class_groups = {}
    for i, (box, mask, conf, cls) in enumerate(zip(boxes, masks, confidences, classes)):
        if cls not in class_groups:
            class_groups[cls] = []
        class_groups[cls].append((i, box, mask, conf, cls))
    
    # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¤‘ë³µ ì œê±°
    keep_indices = []
    
    for class_name, group in class_groups.items():
        if len(group) == 1:
            # í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë¿ì´ë©´ ë°”ë¡œ ì¶”ê°€
            keep_indices.append(group[0][0])
        else:
            # ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œ ì¤‘ë³µ ì œê±°
            group_boxes = [item[1] for item in group]
            group_confidences = [item[3] for item in group]
            group_indices = [item[0] for item in group]
            
            # ë°•ìŠ¤ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            boxes_np = np.array(group_boxes)
            confidences_np = np.array(group_confidences)
            
            # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_indices = np.argsort(confidences_np)[::-1]
            
            class_keep_indices = []
            
            while len(sorted_indices) > 0:
                # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ë°•ìŠ¤ ì„ íƒ
                current_index = sorted_indices[0]
                class_keep_indices.append(group_indices[current_index])
                
                if len(sorted_indices) == 1:
                    break
                
                # í˜„ì¬ ë°•ìŠ¤
                current_box = boxes_np[current_index]
                
                # ë‚˜ë¨¸ì§€ ë°•ìŠ¤ë“¤ê³¼ IoU ê³„ì‚°
                remaining_indices = sorted_indices[1:]
                remaining_boxes = boxes_np[remaining_indices]
                
                # IoU ê³„ì‚°
                ious = calculate_iou(current_box, remaining_boxes)
                
                # IoUê°€ ì„ê³„ê°’ë³´ë‹¤ ë‚®ì€ ë°•ìŠ¤ë“¤ë§Œ ìœ ì§€
                low_iou_indices = np.where(ious < iou_threshold)[0]
                sorted_indices = remaining_indices[low_iou_indices]
            
            keep_indices.extend(class_keep_indices)
    
    # ê²°ê³¼ ë°˜í™˜
    filtered_boxes = [boxes[i] for i in keep_indices]
    filtered_masks = [masks[i] for i in keep_indices] if masks else []
    filtered_confidences = [confidences[i] for i in keep_indices]
    filtered_classes = [classes[i] for i in keep_indices]
    
    return filtered_boxes, filtered_masks, filtered_confidences, filtered_classes

def calculate_iou(box1, boxes):
    """IoU (Intersection over Union) ê³„ì‚°"""
    # box1: [x1, y1, x2, y2]
    # boxes: [[x1, y1, x2, y2], ...]
    
    x1 = np.maximum(box1[0], boxes[:, 0])
    y1 = np.maximum(box1[1], boxes[:, 1])
    x2 = np.minimum(box1[2], boxes[:, 2])
    y2 = np.minimum(box1[3], boxes[:, 3])
    
    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)
    
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    
    union = area1 + area2 - intersection
    
    return intersection / (union + 1e-6)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

def process_detection_results(results, confidence_threshold=0.3, iou_threshold=0.5):
    """ê²€ì¶œ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ì¤‘ë³µ ì œê±°"""
    all_boxes = []
    all_masks = []
    all_confidences = []
    all_classes = []
    
    for result in results:
        boxes = result.boxes
        masks = result.masks
        
        if boxes is not None:
            for i, box in enumerate(boxes):
                confidence = float(box.conf[0].cpu().numpy())
                
                # ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸
                if confidence < confidence_threshold:
                    continue
                
                cls = int(box.cls[0].cpu().numpy())
                class_name = result.names[cls]
                bbox = box.xyxy[0].cpu().numpy().tolist()
                
                all_boxes.append(bbox)
                all_confidences.append(confidence)
                all_classes.append(class_name)
                
                # ë§ˆìŠ¤í¬ ì¶”ê°€
                if masks is not None and i < len(masks.data):
                    mask_data = masks.data[i].cpu().numpy()
                    all_masks.append(mask_data)
                else:
                    all_masks.append(None)
    
    # ì¤‘ë³µ ì œê±°
    filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = remove_duplicates(
        all_boxes, all_masks, all_confidences, all_classes, iou_threshold
    )
    
    return filtered_boxes, filtered_masks, filtered_confidences, filtered_classes

def download_image_from_url(url):
    """URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        image_array = np.frombuffer(response.content, dtype=np.uint8)
        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return image
    except Exception as e:
        raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

def get_image_from_request():
    """ìš”ì²­ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    image = None
    is_gif = False
    gif_bytes = None
    
    # íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
    if 'image' in request.files:
        file = request.files['image']
        if file.filename != '':
            image_bytes = file.read()
            
            # GIF íŒŒì¼ì¸ì§€ í™•ì¸
            if is_gif_image(image_bytes):
                is_gif = True
                gif_bytes = image_bytes
                # GIFì˜ ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ ì‚¬ìš©
                gif = imageio.mimread(gif_bytes, format='gif')
                if gif:
                    frame = gif[0]
                    if len(frame.shape) == 3 and frame.shape[2] == 4:  # RGBA
                        frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
                    elif len(frame.shape) == 3 and frame.shape[2] == 3:  # RGB
                        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    image = frame
            else:
                # ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬
                image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
    
    # URL ì—…ë¡œë“œ í™•ì¸
    elif 'image_url' in request.form and request.form['image_url'].strip():
        url = request.form['image_url'].strip()
        if not url:
            raise ValueError('ì´ë¯¸ì§€ URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
        
        parsed_url = urlparse(url)
        if not parsed_url.scheme or not parsed_url.netloc:
            raise ValueError('ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤')
        
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        image_bytes = response.content
        
        # GIF íŒŒì¼ì¸ì§€ í™•ì¸
        if is_gif_image(image_bytes):
            is_gif = True
            gif_bytes = image_bytes
            # GIFì˜ ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ ì‚¬ìš©
            gif = imageio.mimread(gif_bytes, format='gif')
            if gif:
                frame = gif[0]
                if len(frame.shape) == 3 and frame.shape[2] == 4:  # RGBA
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
                elif len(frame.shape) == 3 and frame.shape[2] == 3:  # RGB
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                image = frame
        else:
            # ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬
            image_array = np.frombuffer(image_bytes, dtype=np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
    
    else:
        raise ValueError('ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” URLì´ í•„ìš”í•©ë‹ˆë‹¤')
    
    if image is None:
        raise ValueError('ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
    
    return image, is_gif, gif_bytes

# 1. ë°°ê²½ ì œê±° ì„œë¹„ìŠ¤
@app.route('/service/remove_background', methods=['POST'])
def remove_background_service():
    """ë°°ê²½ ì œê±° ì„œë¹„ìŠ¤"""
    try:
        print("ğŸ” ë°°ê²½ ì œê±° ì„œë¹„ìŠ¤ ì‹œì‘...")
        image, is_gif, gif_bytes = get_image_from_request()
        print(f"ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ - í¬ê¸°: {image.shape if image is not None else 'None'}")
        
        target_class = request.form.get('target_class', 'person')
        iou_threshold = float(request.form.get('iou_threshold', 0.5))
        mask_precision = float(request.form.get('mask_precision', 0.3))
        print(f"ì„¤ì •ê°’ - ëŒ€ìƒ: {target_class}, IoU: {iou_threshold}, ì •ë°€ë„: {mask_precision}")
        
        # GIF íŒŒì¼ì¸ ê²½ìš°
        if is_gif and gif_bytes:
            print("GIF íŒŒì¼ ê°ì§€ - í”„ë ˆì„ë³„ ì²˜ë¦¬ ì‹œì‘")
            
            # GIFì˜ ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬
            processed_frames = process_gif_frames(
                gif_bytes, 
                target_class=target_class, 
                iou_threshold=iou_threshold, 
                mask_precision=mask_precision, 
                service_type='background_removal'
            )
            
            # ê²°ê³¼ GIF ì €ì¥
            result_filename = f"bg_removed_{target_class}_{len(os.listdir(RESULTS_FOLDER))}.gif"
            result_path = os.path.join(RESULTS_FOLDER, result_filename)
            
            # RGBA í”„ë ˆì„ë“¤ì„ RGBë¡œ ë³€í™˜í•˜ì—¬ GIF ì €ì¥
            rgb_frames = []
            for frame in processed_frames:
                if frame.shape[2] == 4:  # RGBA
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)
                else:  # BGR
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                rgb_frames.append(rgb_frame)
            
            imageio.mimsave(result_path, rgb_frames, format='gif', duration=0.1, loop=0)
            print(f"GIF ê²°ê³¼ ì €ì¥: {result_path}")
            
            # ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ ì‚¬ìš©
            preview_frame = processed_frames[0]
            if preview_frame.shape[2] == 4:  # RGBA
                preview_frame = cv2.cvtColor(preview_frame, cv2.COLOR_BGRA2BGR)
            
            # base64 ì¸ì½”ë”© (ë¯¸ë¦¬ë³´ê¸°ìš©)
            _, buffer = cv2.imencode('.jpg', preview_frame)
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            
            return jsonify({
                'success': True,
                'result_image': img_base64,
                'filename': result_filename,
                'service': 'remove_background',
                'is_gif': True,
                'frame_count': len(processed_frames),
                'duplicates_removed': True,
                'iou_threshold': iou_threshold,
                'target_class': target_class
            })
        
        # ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
        print("ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        print(f"YOLO ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ - ê²°ê³¼ ìˆ˜: {len(results)}")
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=iou_threshold
        )
        print(f"ì¤‘ë³µ ì œê±° ì™„ë£Œ - ê²€ì¶œëœ ê°ì²´: {len(filtered_boxes)}ê°œ")
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        extracted_objects = []
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            print(f"ê°ì²´ {i+1}: {class_name} (ì‹ ë¢°ë„: {confidence:.2f}, ë§ˆìŠ¤í¬: {'ìˆìŒ' if mask_data is not None else 'ì—†ìŒ'})")
            # ëª¨ë“  ê°ì²´ ì„ íƒ ë˜ëŠ” íŠ¹ì • í´ë˜ìŠ¤ ì„ íƒ
            if (target_class == 'all' or class_name == target_class) and mask_data is not None:
                print(f"  -> {class_name} ê°ì²´ ì²˜ë¦¬ ì¤‘...")
                # ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
                object_mask = create_precise_mask(
                    mask_data, 
                    image.shape, 
                    threshold=mask_precision,  # ì‚¬ìš©ì ì„¤ì • ì •ë°€ë„ ì‚¬ìš©
                    refine=True     # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ ì ìš©
                )
                mask = np.maximum(mask, object_mask)
                
                # bboxê°€ numpy ë°°ì—´ì¸ì§€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                if hasattr(bbox, 'tolist'):
                    bbox_list = bbox.tolist()
                else:
                    bbox_list = bbox
                
                extracted_objects.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': bbox_list
                })
        
        print(f"ì¶”ì¶œëœ ê°ì²´ ìˆ˜: {len(extracted_objects)}ê°œ")
        
        if len(extracted_objects) == 0:
            return jsonify({'error': f'ì„ íƒí•œ ëŒ€ìƒ ê°ì²´({target_class})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ë°°ê²½ ì œê±°
        print("ë°°ê²½ ì œê±° ì²˜ë¦¬ ì¤‘...")
        # 1. ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥ (ë°ì´í„° íƒ€ì… ì£¼ì˜)
        mask_normalized = mask.astype(np.float32) / 255.0
        mask_3d = np.stack([mask_normalized] * 3, axis=2)
        
        # 2. ê°ì²´ë§Œ ì¶”ì¶œ
        result_image = image * mask_3d
        
        # 3. íˆ¬ëª… ë°°ê²½ì„ ìœ„í•´ RGBAë¡œ ë³€í™˜
        rgba_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2BGRA)
        rgba_image[:, :, 3] = mask  # ì•ŒíŒŒ ì±„ë„ ì„¤ì •
        
        # ê²°ê³¼ ì €ì¥ (PNGë¡œ ì €ì¥í•˜ì—¬ íˆ¬ëª…ë„ ìœ ì§€)
        result_filename = f"bg_removed_{target_class}_{len(os.listdir(RESULTS_FOLDER))}.png"
        result_path = os.path.join(RESULTS_FOLDER, result_filename)
        cv2.imwrite(result_path, rgba_image)
        print(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_path}")
        
        # ì›¹ í‘œì‹œìš©ìœ¼ë¡œëŠ” BGR ì´ë¯¸ì§€ ì‚¬ìš©
        _, buffer = cv2.imencode('.jpg', result_image)
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        print("âœ… ë°°ê²½ ì œê±° ì„œë¹„ìŠ¤ ì™„ë£Œ!")
        return jsonify({
            'success': True,
            'result_image': img_base64,
            'filename': result_filename,
            'service': 'remove_background',
            'detected_objects': len(filtered_boxes),
            'extracted_objects': extracted_objects,
            'duplicates_removed': True,
            'iou_threshold': iou_threshold,
            'target_class': target_class
        })
        
    except Exception as e:
        print(f"âŒ ë°°ê²½ ì œê±° ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# 2. ê°ì²´ ì¶”ì¶œ ì„œë¹„ìŠ¤
@app.route('/service/extract_objects', methods=['POST'])
def extract_objects_service():
    """ê°ì²´ ì¶”ì¶œ ì„œë¹„ìŠ¤"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        target_classes = request.form.get('target_classes', '').split(',')
        if target_classes == ['']:
            target_classes = None
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=0.5
        )
        
        extracted_objects = []
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            if target_classes is None or class_name in target_classes:
                if mask_data is not None:
                    # ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
                    object_mask = create_precise_mask(
                        mask_data, 
                        image.shape, 
                        threshold=0.3,  # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í”½ì…€ í¬í•¨
                        refine=True     # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ ì ìš©
                    )
                    
                    # ë§ˆìŠ¤í¬ë¥¼ ë¶ˆë¦° ë°°ì—´ë¡œ ë³€í™˜
                    mask_bool = object_mask > 0
                    
                    # ê°ì²´ ì¶”ì¶œ
                    extracted = image.copy()
                    extracted[~mask_bool] = [255, 255, 255]
                    
                    # ê°œë³„ ê°ì²´ ì €ì¥
                    obj_filename = f"extracted_{class_name}_{len(extracted_objects)}.png"
                    obj_path = os.path.join(RESULTS_FOLDER, obj_filename)
                    cv2.imwrite(obj_path, extracted)
                    
                    extracted_objects.append({
                        'class': class_name,
                        'filename': obj_filename,
                        'bbox': bbox,
                        'confidence': confidence
                    })
        
        return jsonify({
            'success': True,
            'extracted_objects': extracted_objects,
            'total_objects': len(extracted_objects),
            'service': 'object_extraction',
            'duplicates_removed': True
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# 3. ì–¼êµ´ ë·°í‹° ì„œë¹„ìŠ¤
@app.route('/service/face_beauty', methods=['POST'])
def face_beauty_service():
    """ì–¼êµ´ ë·°í‹° ì„œë¹„ìŠ¤"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        
        # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb_image)
        
        result_image = image.copy()
        
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                h, w, _ = image.shape
                
                # ì–¼êµ´ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„±
                face_mask = np.zeros((h, w), dtype=np.uint8)
                
                # ì–¼êµ´ ìœ¤ê³½ ëœë“œë§ˆí¬
                face_oval_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,
                                   397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,
                                   172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109, 10]
                
                face_points = []
                for idx in face_oval_indices:
                    if idx < len(face_landmarks.landmark):
                        landmark = face_landmarks.landmark[idx]
                        x = int(landmark.x * w)
                        y = int(landmark.y * h)
                        face_points.append([x, y])
                
                if len(face_points) > 2:
                    # ì–¼êµ´ ë§ˆìŠ¤í¬ ìƒì„±
                    face_points = np.array(face_points, dtype=np.int32)
                    cv2.fillPoly(face_mask, [face_points], 255)
                    
                    # ë·°í‹° í•„í„° ì ìš©
                    # 1. ìŠ¤ë¬´ë”© (ë¸”ëŸ¬)
                    smoothed = cv2.GaussianBlur(result_image, (5, 5), 0)
                    result_image = np.where(face_mask[:, :, np.newaxis] > 0, 
                                          smoothed, result_image)
                    
                    # 2. ë°ê¸° ì¡°ì •
                    hsv = cv2.cvtColor(result_image, cv2.COLOR_BGR2HSV)
                    hsv[face_mask > 0, 2] = np.clip(hsv[face_mask > 0, 2] * 1.1, 0, 255)
                    result_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        # ê²°ê³¼ ì €ì¥
        result_filename = f"beauty_{len(os.listdir(RESULTS_FOLDER))}.jpg"
        result_path = os.path.join(RESULTS_FOLDER, result_filename)
        cv2.imwrite(result_path, result_image)
        
        # base64 ì¸ì½”ë”©
        _, buffer = cv2.imencode('.jpg', result_image)
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return jsonify({
            'success': True,
            'result_image': img_base64,
            'filename': result_filename,
            'service': 'face_beauty'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# 4. ê°ì²´ ì¹´ìš´íŒ… ì„œë¹„ìŠ¤
@app.route('/service/count_objects', methods=['POST'])
def count_objects_service():
    """ê°ì²´ ì¹´ìš´íŒ… ì„œë¹„ìŠ¤"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        target_classes = request.form.get('target_classes', '').split(',')
        if target_classes == ['']:
            target_classes = None
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=0.5
        )
        
        object_counts = {}
        object_details = []
        
        for bbox, confidence, class_name in zip(filtered_boxes, filtered_confidences, filtered_classes):
            if target_classes is None or class_name in target_classes:
                object_counts[class_name] = object_counts.get(class_name, 0) + 1
                object_details.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': bbox
                })
        
        return jsonify({
            'success': True,
            'object_counts': object_counts,
            'object_details': object_details,
            'total_objects': sum(object_counts.values()),
            'service': 'object_counting',
            'duplicates_removed': True
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# 5. ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤
@app.route('/service/analyze_image', methods=['POST'])
def analyze_image_service():
    """ì´ë¯¸ì§€ ì¢…í•© ë¶„ì„ ì„œë¹„ìŠ¤"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=0.5
        )
        
        analysis = {
            'objects': [],
            'total_objects': 0,
            'image_size': image.shape,
            'dominant_objects': [],
            'object_counts': {}
        }
        
        object_counts = {}
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            # ê°ì²´ ì •ë³´
            obj_info = {
                'class': class_name,
                'confidence': confidence,
                'bbox': bbox,
                'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
            }
            
            # ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ê°€
            if mask_data is not None:
                mask_resized = cv2.resize(mask_data, (image.shape[1], image.shape[0]))
                mask_area = np.sum(mask_resized > 0.5)
                obj_info['mask_area'] = int(mask_area)
            
            analysis['objects'].append(obj_info)
            object_counts[class_name] = object_counts.get(class_name, 0) + 1
        
        analysis['total_objects'] = len(analysis['objects'])
        analysis['object_counts'] = object_counts
        
        # ì£¼ìš” ê°ì²´ ì°¾ê¸° (ë©´ì  ê¸°ì¤€)
        if analysis['objects']:
            sorted_objects = sorted(analysis['objects'], key=lambda x: x.get('mask_area', 0), reverse=True)
            analysis['dominant_objects'] = [obj['class'] for obj in sorted_objects[:3]]
        
        return jsonify({
            'success': True,
            'analysis': analysis,
            'service': 'image_analysis',
            'duplicates_removed': True
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# 6. ì´ë¯¸ì§€ í•„í„° ì„œë¹„ìŠ¤
@app.route('/service/apply_filter', methods=['POST'])
def apply_filter_service():
    """ì´ë¯¸ì§€ í•„í„° ì ìš© ì„œë¹„ìŠ¤"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        filter_type = request.form.get('filter_type', 'blur')
        target_class = request.form.get('target_class', 'person')
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=0.5
        )
        
        result_image = image.copy()
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            if class_name == target_class and mask_data is not None:
                # ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
                object_mask = create_precise_mask(
                    mask_data, 
                    image.shape, 
                    threshold=0.3,  # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í”½ì…€ í¬í•¨
                    refine=True     # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ ì ìš©
                )
                
                # ë§ˆìŠ¤í¬ë¥¼ ë¶ˆë¦° ë°°ì—´ë¡œ ë³€í™˜
                mask_bool = object_mask > 0
                
                # í•„í„° ì ìš©
                if filter_type == 'blur':
                    blurred = cv2.GaussianBlur(result_image, (15, 15), 0)
                    result_image[mask_bool] = blurred[mask_bool]
                elif filter_type == 'brightness':
                    hsv = cv2.cvtColor(result_image, cv2.COLOR_BGR2HSV)
                    hsv[mask_bool, 2] = np.clip(hsv[mask_bool, 2] * 1.5, 0, 255)
                    result_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                elif filter_type == 'contrast':
                    lab = cv2.cvtColor(result_image, cv2.COLOR_BGR2LAB)
                    lab[mask_bool, 0] = np.clip(lab[mask_bool, 0] * 1.3, 0, 255)
                    result_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # ê²°ê³¼ ì €ì¥
        result_filename = f"filtered_{filter_type}_{len(os.listdir(RESULTS_FOLDER))}.jpg"
        result_path = os.path.join(RESULTS_FOLDER, result_filename)
        cv2.imwrite(result_path, result_image)
        
        # base64 ì¸ì½”ë”©
        _, buffer = cv2.imencode('.jpg', result_image)
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return jsonify({
            'success': True,
            'result_image': img_base64,
            'filename': result_filename,
            'filter_type': filter_type,
            'service': 'image_filter',
            'duplicates_removed': True
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ê²€ì¶œëœ ê°ì²´ ëª©ë¡ ë°˜í™˜
@app.route('/service/get_detected_objects', methods=['POST'])
def get_detected_objects_service():
    """ê²€ì¶œëœ ê°ì²´ ëª©ë¡ ë°˜í™˜"""
    try:
        image, is_gif, gif_bytes = get_image_from_request()
        iou_threshold = float(request.form.get('iou_threshold', 0.5))
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=iou_threshold
        )
        
        # ê²€ì¶œëœ ê°ì²´ë“¤ì˜ ê³ ìœ í•œ í´ë˜ìŠ¤ ëª©ë¡
        unique_classes = list(set(filtered_classes))
        
        return jsonify({
            'success': True,
            'detected_classes': unique_classes,
            'total_objects': len(filtered_classes),
            'object_counts': {cls: filtered_classes.count(cls) for cls in unique_classes}
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤
@app.route('/service/background_composition', methods=['POST'])
def background_composition_service():
    """ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤"""
    try:
        print("ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤ ì‹œì‘")
        print(f"ìš”ì²­ íŒŒì¼: {list(request.files.keys())}")
        print(f"ìš”ì²­ í¼ ë°ì´í„°: {list(request.form.keys())}")
        
        # ì›ë³¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        original_image, is_gif, gif_bytes = get_image_from_request()
        print(f"ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {original_image.shape}")
        
        target_class = request.form.get('target_class', 'person')
        iou_threshold = float(request.form.get('iou_threshold', 0.5))
        mask_precision = float(request.form.get('mask_precision', 0.3))
        print(f"ëŒ€ìƒ í´ë˜ìŠ¤: {target_class}, IoU ì„ê³„ê°’: {iou_threshold}")
        
        # ìƒˆ ë°°ê²½ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        background_image = None
        background_gif_frames = None
        
        # ìƒˆ ë°°ê²½ íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
        if 'background_image' in request.files:
            file = request.files['background_image']
            if file.filename != '':
                print(f"ë°°ê²½ ì´ë¯¸ì§€ íŒŒì¼: {file.filename}")
                image_bytes = file.read()
                if is_gif_image(image_bytes):
                    print("ë°°ê²½ ì´ë¯¸ì§€ê°€ GIFì…ë‹ˆë‹¤.")
                    import imageio
                    background_gif_frames = imageio.mimread(image_bytes, format='gif')
                    print(f"ë°°ê²½ GIF í”„ë ˆì„ ìˆ˜: {len(background_gif_frames)}")
                    # ì²« í”„ë ˆì„ì„ ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ ì‚¬ìš©
                    background_image = background_gif_frames[0]
                    if len(background_image.shape) == 3 and background_image.shape[2] == 4:
                        background_image = cv2.cvtColor(background_image, cv2.COLOR_RGBA2BGR)
                    elif len(background_image.shape) == 3 and background_image.shape[2] == 3:
                        background_image = cv2.cvtColor(background_image, cv2.COLOR_RGB2BGR)
                else:
                    background_image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
                    print(f"ë°°ê²½ ì´ë¯¸ì§€ í¬ê¸°: {background_image.shape if background_image is not None else 'None'}")
        
        # ìƒˆ ë°°ê²½ URL í™•ì¸
        elif 'background_url' in request.form and request.form['background_url'].strip():
            url = request.form['background_url'].strip()
            print(f"ë°°ê²½ ì´ë¯¸ì§€ URL: {url}")
            if url:
                parsed_url = urlparse(url)
                if parsed_url.scheme and parsed_url.netloc:
                    background_image = download_image_from_url(url)
                    print(f"ë°°ê²½ ì´ë¯¸ì§€ í¬ê¸°: {background_image.shape if background_image is not None else 'None'}")
        
        if background_image is None:
            return jsonify({'error': 'ìƒˆ ë°°ê²½ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # GIF íŒŒì¼ì¸ ê²½ìš°
        if is_gif and gif_bytes:
            print("GIF íŒŒì¼ ê°ì§€ - í”„ë ˆì„ë³„ ë°°ê²½ í•©ì„± ì‹œì‘")
            import imageio
            # ë©”ì¸ GIF í”„ë ˆì„ ì¶”ì¶œ
            main_gif_frames = imageio.mimread(gif_bytes, format='gif')
            main_frame_count = len(main_gif_frames)
            print(f"ë©”ì¸ GIF í”„ë ˆì„ ìˆ˜: {main_frame_count}")
            # ë°°ê²½ í”„ë ˆì„ ì¤€ë¹„
            if background_gif_frames is not None:
                bg_frame_count = len(background_gif_frames)
                # ë°°ê²½ í”„ë ˆì„ì„ ë©”ì¸ í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ ë°˜ë³µ ë˜ëŠ” ìë¦„
                if bg_frame_count < main_frame_count:
                    repeat = (main_frame_count + bg_frame_count - 1) // bg_frame_count
                    background_gif_frames = (background_gif_frames * repeat)[:main_frame_count]
                elif bg_frame_count > main_frame_count:
                    background_gif_frames = background_gif_frames[:main_frame_count]
            else:
                # ë‹¨ì¼ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ëª¨ë“  í”„ë ˆì„ì— ì‚¬ìš©
                background_gif_frames = [background_image] * main_frame_count
            processed_frames = []
            for i, (main_frame, bg_frame) in enumerate(zip(main_gif_frames, background_gif_frames)):
                print(f"í”„ë ˆì„ {i+1}/{main_frame_count} í•©ì„± ì¤‘...")
                # í”„ë ˆì„ ìƒ‰ìƒ ë³€í™˜
                if len(main_frame.shape) == 3 and main_frame.shape[2] == 4:
                    main_frame_bgr = cv2.cvtColor(main_frame, cv2.COLOR_RGBA2BGR)
                elif len(main_frame.shape) == 3 and main_frame.shape[2] == 3:
                    main_frame_bgr = cv2.cvtColor(main_frame, cv2.COLOR_RGB2BGR)
                else:
                    main_frame_bgr = main_frame
                if len(bg_frame.shape) == 3 and bg_frame.shape[2] == 4:
                    bg_bgr = cv2.cvtColor(bg_frame, cv2.COLOR_RGBA2BGR)
                elif len(bg_frame.shape) == 3 and bg_frame.shape[2] == 3:
                    bg_bgr = cv2.cvtColor(bg_frame, cv2.COLOR_RGB2BGR)
                else:
                    bg_bgr = bg_frame
                # ë°°ê²½ ë¦¬ì‚¬ì´ì¦ˆ
                bg_bgr = cv2.resize(bg_bgr, (main_frame_bgr.shape[1], main_frame_bgr.shape[0]))
                # ê°ì²´ ê°ì§€ ë° ë§ˆìŠ¤í¬ ìƒì„±
                results = yolo_model(main_frame_bgr)
                filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
                    results, confidence_threshold=0.3, iou_threshold=iou_threshold
                )
                mask = np.zeros(main_frame_bgr.shape[:2], dtype=np.uint8)
                for bbox, mask_data, confidence, class_name in zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes):
                    if (target_class == 'all' or class_name == target_class) and mask_data is not None:
                        object_mask = create_precise_mask(
                            mask_data, 
                            main_frame_bgr.shape, 
                            threshold=mask_precision, 
                            refine=True
                        )
                        mask = np.maximum(mask, object_mask)
                mask_normalized = mask.astype(np.float32) / 255.0
                mask_3d = np.stack([mask_normalized] * 3, axis=2)
                result_frame = main_frame_bgr * mask_3d + bg_bgr * (1 - mask_3d)
                result_frame = result_frame.astype(np.uint8)
                processed_frames.append(result_frame)
            # ê²°ê³¼ GIF ì €ì¥
            result_filename = f"composed_{target_class}_{len(os.listdir(RESULTS_FOLDER))}.gif"
            result_path = os.path.join(RESULTS_FOLDER, result_filename)
            rgb_frames = [cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in processed_frames]
            imageio.mimsave(result_path, rgb_frames, format='gif', duration=0.1, loop=0)
            print(f"GIF ê²°ê³¼ ì €ì¥: {result_path}")
            preview_frame = processed_frames[0]
            _, buffer = cv2.imencode('.jpg', preview_frame)
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            return jsonify({
                'success': True,
                'result_image': img_base64,
                'filename': result_filename,
                'service': 'background_composition',
                'is_gif': True,
                'frame_count': len(processed_frames),
                'duplicates_removed': True,
                'iou_threshold': iou_threshold,
                'target_class': target_class
            })
        
        # ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
        # ê°ì²´ ê°ì§€
        print("ê°ì²´ ê°ì§€ ì‹œì‘")
        results = yolo_model(original_image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=iou_threshold
        )
        print(f"ê²€ì¶œëœ ê°ì²´: {filtered_classes}")
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
        composed_objects = []
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            # ëª¨ë“  ê°ì²´ ì„ íƒ ë˜ëŠ” íŠ¹ì • í´ë˜ìŠ¤ ì„ íƒ
            if (target_class == 'all' or class_name == target_class) and mask_data is not None:
                # ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
                object_mask = create_precise_mask(
                    mask_data, 
                    original_image.shape, 
                    threshold=mask_precision,  # ì‚¬ìš©ì ì„¤ì • ì •ë°€ë„ ì‚¬ìš©
                    refine=True     # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ ì ìš©
                )
                mask = np.maximum(mask, object_mask)
                
                # bboxê°€ numpy ë°°ì—´ì¸ì§€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                if hasattr(bbox, 'tolist'):
                    bbox_list = bbox.tolist()
                else:
                    bbox_list = bbox
                
                composed_objects.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': bbox_list
                })
                print(f"{class_name} ê°ì²´ {i+1}: ì‹ ë¢°ë„ {confidence:.2f}")
        
        print(f"í•©ì„±í•  ê°ì²´ ìˆ˜: {len(composed_objects)}")
        
        if len(composed_objects) == 0:
            return jsonify({'error': f'ì„ íƒí•œ ëŒ€ìƒ ê°ì²´({target_class})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ë°°ê²½ í•©ì„±
        print("ë°°ê²½ í•©ì„± ì‹œì‘")
        # 1. ìƒˆ ë°°ê²½ì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        background_resized = cv2.resize(background_image, (original_image.shape[1], original_image.shape[0]))
        
        # 2. ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥ (ë°ì´í„° íƒ€ì… ì£¼ì˜)
        mask_normalized = mask.astype(np.float32) / 255.0
        mask_3d = np.stack([mask_normalized] * 3, axis=2)
        
        # 3. ê°ì²´ì™€ ë°°ê²½ í•©ì„±
        result_image = original_image * mask_3d + background_resized * (1 - mask_3d)
        result_image = result_image.astype(np.uint8)
        
        # ê²°ê³¼ ì €ì¥
        result_filename = f"composed_{target_class}_{len(os.listdir(RESULTS_FOLDER))}.jpg"
        result_path = os.path.join(RESULTS_FOLDER, result_filename)
        cv2.imwrite(result_path, result_image)
        print(f"ê²°ê³¼ ì €ì¥: {result_path}")
        
        # base64 ì¸ì½”ë”©
        _, buffer = cv2.imencode('.jpg', result_image)
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        print("ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤ ì™„ë£Œ")
        return jsonify({
            'success': True,
            'result_image': img_base64,
            'filename': result_filename,
            'service': 'background_composition',
            'detected_objects': len(filtered_boxes),
            'composed_objects': composed_objects,
            'duplicates_removed': True,
            'iou_threshold': iou_threshold,
            'target_class': target_class
        })
        
    except ValueError as ve:
        print(f"ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤ ValueError: {str(ve)}")
        return jsonify({'error': str(ve)}), 400
    except Exception as e:
        print(f"ë°°ê²½ í•©ì„± ì„œë¹„ìŠ¤ ì˜ˆì™¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

def demo_background_composition():
    """ë°°ê²½ í•©ì„± ë°ëª¨"""
    print("\nğŸ­ ë°°ê²½ í•©ì„± ë°ëª¨")
    print("=" * 50)
    
    # ìƒ˜í”Œ ì´ë¯¸ì§€ URL (ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€)
    sample_image_url = "https://images.unsplash.com/photo-1543852786-1cf6624b9987?w=400"
    
    # ë°°ê²½ ì´ë¯¸ì§€ URL (ìì—° í’ê²½)
    background_url = "https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=400"
    
    print(f"ì›ë³¸ ì´ë¯¸ì§€: {sample_image_url}")
    print(f"ìƒˆ ë°°ê²½: {background_url}")
    
    try:
        # ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        original_image = download_image_from_url(sample_image_url)
        if original_image is None:
            print("âŒ ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return
        
        # ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        background_image = download_image_from_url(background_url)
        if background_image is None:
            print("âŒ ë°°ê²½ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return
        
        print("âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        # ê°ì²´ ê°ì§€
        results = yolo_model(original_image)
        
        # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
        filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
            results, confidence_threshold=0.3, iou_threshold=0.5
        )
        
        print(f"ê²€ì¶œëœ ê°ì²´: {filtered_classes}")
        
        # ëª¨ë“  ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
        mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
        composed_objects = []
        
        for i, (bbox, mask_data, confidence, class_name) in enumerate(zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes)):
            if mask_data is not None:
                # ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
                object_mask = create_precise_mask(
                    mask_data, 
                    original_image.shape, 
                    threshold=0.3,  # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í”½ì…€ í¬í•¨
                    refine=True     # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ ì ìš©
                )
                mask = np.maximum(mask, object_mask)
                
                # bboxê°€ numpy ë°°ì—´ì¸ì§€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                if hasattr(bbox, 'tolist'):
                    bbox_list = bbox.tolist()
                else:
                    bbox_list = bbox
                
                composed_objects.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': bbox_list
                })
                print(f"{class_name} ê°ì²´ {i+1}: ì‹ ë¢°ë„ {confidence:.2f}")
        
        if len(composed_objects) == 0:
            print("âŒ ê²€ì¶œëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print(f"í•©ì„±í•  ê°ì²´ ìˆ˜: {len(composed_objects)}ê°œ")
        
        # ë°°ê²½ í•©ì„±
        # 1. ìƒˆ ë°°ê²½ì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        background_resized = cv2.resize(background_image, (original_image.shape[1], original_image.shape[0]))
        
        # 2. ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥ (ë°ì´í„° íƒ€ì… ì£¼ì˜)
        mask_normalized = mask.astype(np.float32) / 255.0
        mask_3d = np.stack([mask_normalized] * 3, axis=2)
        
        # 3. ê°ì²´ì™€ ë°°ê²½ í•©ì„±
        result_image = original_image * mask_3d + background_resized * (1 - mask_3d)
        result_image = result_image.astype(np.uint8)
        
        # ê²°ê³¼ ì €ì¥
        result_filename = f"composed_all_{len(os.listdir(RESULTS_FOLDER))}.jpg"
        result_path = os.path.join(RESULTS_FOLDER, result_filename)
        cv2.imwrite(result_path, result_image)
        
        print(f"âœ… ë°°ê²½ í•©ì„± ì™„ë£Œ: {result_filename}")
        print(f"ì €ì¥ ìœ„ì¹˜: {result_path}")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        print(f"ì›ë³¸ í¬ê¸°: {original_image.shape[1]}x{original_image.shape[0]}")
        print(f"ë°°ê²½ í¬ê¸°: {background_image.shape[1]}x{background_image.shape[0]}")
        print(f"ê²°ê³¼ í¬ê¸°: {result_image.shape[1]}x{result_image.shape[0]}")
        
        # í•©ì„±ëœ ê°ì²´ ì •ë³´
        print(f"í•©ì„±ëœ ê°ì²´: {[obj['class'] for obj in composed_objects]}")
        
    except Exception as e:
        print(f"âŒ ë°°ê²½ í•©ì„± ì‹¤íŒ¨: {str(e)}")

def refine_mask(mask, kernel_size=3, iterations=1):
    """ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒì„ ìœ„í•œ í›„ì²˜ë¦¬"""
    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # ì—´ê¸° ì—°ì‚° (erosion + dilation) - ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=iterations)
    
    # ë‹«ê¸° ì—°ì‚° (dilation + erosion) - ì‘ì€ êµ¬ë© ë©”ìš°ê¸°
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    
    return mask

def create_precise_mask(mask_data, target_shape, threshold=0.3, refine=True):
    """ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±"""
    # mask_dataê°€ Noneì¸ ê²½ìš° ë¹ˆ ë§ˆìŠ¤í¬ ë°˜í™˜
    if mask_data is None:
        return np.zeros(target_shape[:2], dtype=np.uint8)
    
    # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
    mask_resized = cv2.resize(mask_data, (target_shape[1], target_shape[0]))
    
    # ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€í™˜ (OpenCV í˜¸í™˜ì„±)
    mask_resized = mask_resized.astype(np.float32)
    
    # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„± (ë” ë§ì€ í”½ì…€ í¬í•¨)
    mask = (mask_resized > threshold).astype(np.uint8) * 255
    
    if refine:
        # ë§ˆìŠ¤í¬ ì •ë°€ë„ í–¥ìƒ
        mask = refine_mask(mask, kernel_size=3, iterations=1)
    
    return mask

# ë©”ì¸ í˜ì´ì§€
@app.route('/')
def index():
    """ì„œë¹„ìŠ¤ ë©”ì¸ í˜ì´ì§€"""
    return render_template('services.html')

# ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
@app.route('/download/<filename>')
def download_result(filename):
    """ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        return send_file(os.path.join(RESULTS_FOLDER, filename), as_attachment=True)
    except FileNotFoundError:
        return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404

def is_gif_image(image_bytes):
    """ì´ë¯¸ì§€ê°€ GIFì¸ì§€ í™•ì¸"""
    try:
        # ì²« ë²ˆì§¸ ë°”ì´íŠ¸ë¡œ GIF ì‹œê·¸ë‹ˆì²˜ í™•ì¸
        return image_bytes[:4] == b'GIF8'
    except:
        return False

def process_gif_frames(gif_bytes, target_class='all', iou_threshold=0.5, mask_precision=0.3, service_type='background_removal'):
    """GIFì˜ ê° í”„ë ˆì„ì„ ì²˜ë¦¬"""
    try:
        # GIF ì½ê¸°
        gif = imageio.mimread(gif_bytes, format='gif')
        
        if not gif:
            raise ValueError("GIFë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"GIF í”„ë ˆì„ ìˆ˜: {len(gif)}")
        
        processed_frames = []
        
        for i, frame in enumerate(gif):
            print(f"í”„ë ˆì„ {i+1}/{len(gif)} ì²˜ë¦¬ ì¤‘...")
            
            # PIL Imageë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if len(frame.shape) == 3 and frame.shape[2] == 4:  # RGBA
                frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
            elif len(frame.shape) == 3 and frame.shape[2] == 3:  # RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            
            # ê°ì²´ ê°ì§€
            results = yolo_model(frame)
            
            # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ ì²˜ë¦¬
            filtered_boxes, filtered_masks, filtered_confidences, filtered_classes = process_detection_results(
                results, confidence_threshold=0.3, iou_threshold=iou_threshold
            )
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            mask = np.zeros(frame.shape[:2], dtype=np.uint8)
            
            for bbox, mask_data, confidence, class_name in zip(filtered_boxes, filtered_masks, filtered_confidences, filtered_classes):
                if (target_class == 'all' or class_name == target_class) and mask_data is not None:
                    object_mask = create_precise_mask(
                        mask_data, 
                        frame.shape, 
                        threshold=mask_precision,
                        refine=True
                    )
                    mask = np.maximum(mask, object_mask)
            
            # ì„œë¹„ìŠ¤ë³„ ì²˜ë¦¬
            if service_type == 'background_removal':
                # ë°°ê²½ ì œê±°
                mask_normalized = mask.astype(np.float32) / 255.0
                mask_3d = np.stack([mask_normalized] * 3, axis=2)
                processed_frame = frame * mask_3d
                
                # ë°ì´í„° íƒ€ì…ì„ uint8ë¡œ ë³€í™˜ (OpenCV í˜¸í™˜ì„±)
                processed_frame = processed_frame.astype(np.uint8)
                
                # RGBAë¡œ ë³€í™˜ (íˆ¬ëª… ë°°ê²½)
                rgba_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2BGRA)
                rgba_frame[:, :, 3] = mask
                processed_frames.append(rgba_frame)
                
            elif service_type == 'background_composition':
                # ë°°ê²½ í•©ì„± (ì²« ë²ˆì§¸ í”„ë ˆì„ì˜ ë°°ê²½ ì‚¬ìš©)
                if i == 0:
                    # ì²« ë²ˆì§¸ í”„ë ˆì„ì€ ì›ë³¸ ë°°ê²½ ì‚¬ìš©
                    processed_frames.append(frame)
                else:
                    # ë‚˜ë¨¸ì§€ í”„ë ˆì„ì€ ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ë°°ê²½ìœ¼ë¡œ ì‚¬ìš©
                    background = processed_frames[0]
                    mask_normalized = mask.astype(np.float32) / 255.0
                    mask_3d = np.stack([mask_normalized] * 3, axis=2)
                    processed_frame = frame * mask_3d + background * (1 - mask_3d)
                    processed_frame = processed_frame.astype(np.uint8)
                    processed_frames.append(processed_frame)
        
        return processed_frames
        
    except Exception as e:
        print(f"GIF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise e

if __name__ == '__main__':
    print("ğŸš€ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„œë¹„ìŠ¤ ì„œë²„ ì‹œì‘...")
    print("ğŸ“± ì›¹ ì¸í„°í˜ì´ìŠ¤: http://localhost:5000")
    print("ğŸ”— ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸:")
    print("  - ë°°ê²½ ì œê±°: /service/remove_background")
    print("  - ë°°ê²½ í•©ì„±: /service/background_composition")
    print("  - ê°ì²´ ì¶”ì¶œ: /service/extract_objects")
    print("  - ì–¼êµ´ ë·°í‹°: /service/face_beauty")
    print("  - ê°ì²´ ì¹´ìš´íŒ…: /service/count_objects")
    print("  - ì´ë¯¸ì§€ ë¶„ì„: /service/analyze_image")
    print("  - ì´ë¯¸ì§€ í•„í„°: /service/apply_filter")
    print("  - ê²€ì¶œëœ ê°ì²´ ëª©ë¡: /service/get_detected_objects")
    
    # ë°ëª¨ ì‹¤í–‰ (ì„ íƒì‚¬í•­)
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == '--demo':
        print("\nğŸ¬ ë°ëª¨ ëª¨ë“œ ì‹¤í–‰...")
        demo_background_composition()
        print("\nâœ… ë°ëª¨ ì™„ë£Œ!")
    
    app.run(debug=True, host='0.0.0.0', port=5000) 